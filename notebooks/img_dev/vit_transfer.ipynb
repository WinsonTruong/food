{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using transfer learning from a ViT model from huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import transformers\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchvision import transforms \n",
    "from torchvision.datasets import Food101\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "from datasets import load_metric, load_dataset\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import DefaultDataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset food101 (C:\\Users\\truon\\.cache\\huggingface\\datasets\\food101\\default\\0.0.0\\7cebe41a80fb2da3f08fcbef769c8874073a86346f7fb96dc0847d4dfc318295)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64387, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11363, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "food = load_dataset(\"food101\", split=\"train\")\n",
    "\n",
    "splits = food.train_test_split(test_size=0.15)\n",
    "train = splits['train']\n",
    "val = splits['test']\n",
    "\n",
    "display(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process image to tensor using ViT method (16x16 patches)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AutoFeatureExtractor.from_pretrained()` method helps us make sure we are \n",
    "- (1) resizing the inputs to the appropriate size \n",
    "- (2) using the appropriate image mean and standard deviation for the model architecture we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 35,\n",
       " 'pixel_values': tensor([[[ 0.4431,  0.4824,  0.5059,  ...,  0.9922,  0.9922,  0.9922],\n",
       "          [ 0.4510,  0.4196,  0.4510,  ...,  0.9922,  0.9843,  0.9843],\n",
       "          [ 0.3490,  0.3490,  0.3490,  ...,  0.9922,  1.0000,  0.9922],\n",
       "          ...,\n",
       "          [ 0.0118,  0.0118, -0.0118,  ...,  0.9216,  0.8980,  0.8902],\n",
       "          [ 0.0118,  0.0039,  0.0196,  ...,  0.9059,  0.9059,  0.8980],\n",
       "          [ 0.0196, -0.0118,  0.0196,  ...,  0.8824,  0.8902,  0.8667]],\n",
       " \n",
       "         [[-0.1294, -0.0745, -0.0353,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [-0.1294, -0.1294, -0.0745,  ...,  1.0000,  0.9922,  0.9922],\n",
       "          [-0.1922, -0.2078, -0.2235,  ...,  0.9922,  0.9922,  1.0000],\n",
       "          ...,\n",
       "          [-0.3569, -0.3490, -0.3725,  ...,  0.4902,  0.4667,  0.4588],\n",
       "          [-0.3490, -0.3490, -0.3333,  ...,  0.4824,  0.4745,  0.4745],\n",
       "          [-0.3333, -0.3647, -0.3333,  ...,  0.4667,  0.4588,  0.4431]],\n",
       " \n",
       "         [[-0.6000, -0.5451, -0.5059,  ...,  0.8824,  0.8824,  0.8824],\n",
       "          [-0.5843, -0.5843, -0.5294,  ...,  0.8745,  0.8667,  0.8667],\n",
       "          [-0.6471, -0.6863, -0.7098,  ...,  0.8353,  0.8431,  0.8510],\n",
       "          ...,\n",
       "          [-0.6000, -0.6078, -0.6392,  ..., -0.4275, -0.4588, -0.4588],\n",
       "          [-0.5922, -0.6078, -0.5922,  ..., -0.4431, -0.4667, -0.4745],\n",
       "          [-0.5765, -0.6078, -0.5843,  ..., -0.4588, -0.4824, -0.5137]]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_transforms = Compose(\n",
    "    [\n",
    "            RandomResizedCrop(feature_extractor.size)\n",
    "            ,ToTensor()\n",
    "            ,normalize\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "# when the data is loaded, it will apply the transformation above\n",
    "train = train.with_transform(transforms)\n",
    "val = val.with_transform(transforms)\n",
    "\n",
    "# example of how our data is organized, dictionary with 2 key-value pairs\n",
    "train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 RGBs, 224 x 224 pixels\n",
    "train[0]['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultDataCollator(return_tensors='pt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~ creating a dataloader, creates batches \n",
    "# `pt` is for PyTorch Tensor\n",
    "data_collator = DefaultDataCollator()\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "labels = train.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\truon\\Documents\\projects\\food\\notebooks\\../102722run is already a clone of https://huggingface.co/stochastic/102722run. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../102722run\",\n",
    "    per_device_train_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=30,\n",
    "    fp16=True,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 64387\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 60390\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwinsontruong\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\truon\\Documents\\projects\\food\\notebooks\\wandb\\run-20221027_203828-2t645oiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/winsontruong/huggingface/runs/2t645oiy\" target=\"_blank\">../102722run</a></strong> to <a href=\"https://wandb.ai/winsontruong/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01900196075439453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 60390,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9eee1d25354236b62e115610df26c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60390 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.5771, 'learning_rate': 0.00019996688193409505, 'epoch': 0.0}\n",
      "{'loss': 4.4866, 'learning_rate': 0.00019993376386819012, 'epoch': 0.01}\n",
      "{'loss': 4.4235, 'learning_rate': 0.00019990064580228516, 'epoch': 0.01}\n",
      "{'loss': 4.2814, 'learning_rate': 0.0001998675277363802, 'epoch': 0.02}\n",
      "{'loss': 4.1408, 'learning_rate': 0.00019983440967047528, 'epoch': 0.02}\n",
      "{'loss': 4.0479, 'learning_rate': 0.00019980129160457032, 'epoch': 0.03}\n",
      "{'loss': 3.9138, 'learning_rate': 0.00019976817353866536, 'epoch': 0.03}\n",
      "{'loss': 3.8012, 'learning_rate': 0.0001997350554727604, 'epoch': 0.04}\n",
      "{'loss': 3.7385, 'learning_rate': 0.00019970193740685544, 'epoch': 0.04}\n",
      "{'loss': 3.5957, 'learning_rate': 0.0001996688193409505, 'epoch': 0.05}\n",
      "{'loss': 3.5138, 'learning_rate': 0.00019963570127504553, 'epoch': 0.05}\n",
      "{'loss': 3.4593, 'learning_rate': 0.0001996025832091406, 'epoch': 0.06}\n",
      "{'loss': 3.2644, 'learning_rate': 0.00019956946514323564, 'epoch': 0.06}\n",
      "{'loss': 3.241, 'learning_rate': 0.00019953634707733068, 'epoch': 0.07}\n",
      "{'loss': 3.1983, 'learning_rate': 0.00019950322901142575, 'epoch': 0.07}\n",
      "{'loss': 3.0973, 'learning_rate': 0.0001994701109455208, 'epoch': 0.08}\n",
      "{'loss': 3.1028, 'learning_rate': 0.00019943699287961584, 'epoch': 0.08}\n",
      "{'loss': 2.989, 'learning_rate': 0.00019940387481371088, 'epoch': 0.09}\n",
      "{'loss': 2.9627, 'learning_rate': 0.00019937075674780595, 'epoch': 0.09}\n",
      "{'loss': 2.7177, 'learning_rate': 0.000199337638681901, 'epoch': 0.1}\n",
      "{'loss': 2.7893, 'learning_rate': 0.00019930452061599603, 'epoch': 0.1}\n",
      "{'loss': 2.7092, 'learning_rate': 0.0001992714025500911, 'epoch': 0.11}\n",
      "{'loss': 2.6152, 'learning_rate': 0.00019923828448418615, 'epoch': 0.11}\n",
      "{'loss': 2.6265, 'learning_rate': 0.0001992051664182812, 'epoch': 0.12}\n",
      "{'loss': 2.5943, 'learning_rate': 0.00019917204835237623, 'epoch': 0.12}\n",
      "{'loss': 2.5089, 'learning_rate': 0.00019913893028647127, 'epoch': 0.13}\n",
      "{'loss': 2.6252, 'learning_rate': 0.00019910581222056632, 'epoch': 0.13}\n",
      "{'loss': 2.4071, 'learning_rate': 0.00019907269415466138, 'epoch': 0.14}\n",
      "{'loss': 2.2508, 'learning_rate': 0.00019903957608875643, 'epoch': 0.14}\n",
      "{'loss': 2.3904, 'learning_rate': 0.00019900645802285147, 'epoch': 0.15}\n",
      "{'loss': 2.419, 'learning_rate': 0.0001989733399569465, 'epoch': 0.15}\n",
      "{'loss': 2.1786, 'learning_rate': 0.00019894022189104158, 'epoch': 0.16}\n",
      "{'loss': 2.2456, 'learning_rate': 0.00019890710382513662, 'epoch': 0.16}\n",
      "{'loss': 2.209, 'learning_rate': 0.00019887398575923167, 'epoch': 0.17}\n",
      "{'loss': 2.044, 'learning_rate': 0.00019884086769332674, 'epoch': 0.17}\n",
      "{'loss': 2.1192, 'learning_rate': 0.00019880774962742178, 'epoch': 0.18}\n",
      "{'loss': 2.1242, 'learning_rate': 0.00019877463156151682, 'epoch': 0.18}\n",
      "{'loss': 2.0369, 'learning_rate': 0.00019874151349561186, 'epoch': 0.19}\n",
      "{'loss': 1.8331, 'learning_rate': 0.0001987083954297069, 'epoch': 0.19}\n",
      "{'loss': 2.0805, 'learning_rate': 0.00019867527736380195, 'epoch': 0.2}\n",
      "{'loss': 2.0177, 'learning_rate': 0.000198642159297897, 'epoch': 0.2}\n",
      "{'loss': 1.7378, 'learning_rate': 0.00019860904123199206, 'epoch': 0.21}\n",
      "{'loss': 1.9074, 'learning_rate': 0.0001985759231660871, 'epoch': 0.21}\n",
      "{'loss': 1.7171, 'learning_rate': 0.00019854280510018214, 'epoch': 0.22}\n",
      "{'loss': 1.7854, 'learning_rate': 0.0001985096870342772, 'epoch': 0.22}\n",
      "{'loss': 1.8617, 'learning_rate': 0.00019847656896837226, 'epoch': 0.23}\n",
      "{'loss': 1.8035, 'learning_rate': 0.0001984434509024673, 'epoch': 0.23}\n",
      "{'loss': 1.8385, 'learning_rate': 0.00019841033283656237, 'epoch': 0.24}\n",
      "{'loss': 1.6192, 'learning_rate': 0.0001983772147706574, 'epoch': 0.24}\n",
      "{'loss': 1.9295, 'learning_rate': 0.00019834409670475245, 'epoch': 0.25}\n",
      "{'loss': 1.6647, 'learning_rate': 0.00019831097863884752, 'epoch': 0.25}\n",
      "{'loss': 1.9222, 'learning_rate': 0.00019828117237953306, 'epoch': 0.26}\n",
      "{'loss': 1.6661, 'learning_rate': 0.0001982480543136281, 'epoch': 0.26}\n",
      "{'loss': 1.6672, 'learning_rate': 0.00019821493624772314, 'epoch': 0.27}\n",
      "{'loss': 1.6286, 'learning_rate': 0.00019818181818181821, 'epoch': 0.27}\n",
      "{'loss': 1.741, 'learning_rate': 0.00019814870011591326, 'epoch': 0.28}\n",
      "{'loss': 1.7837, 'learning_rate': 0.0001981155820500083, 'epoch': 0.28}\n",
      "{'loss': 1.5995, 'learning_rate': 0.00019808246398410334, 'epoch': 0.29}\n",
      "{'loss': 1.6068, 'learning_rate': 0.00019804934591819838, 'epoch': 0.29}\n",
      "{'loss': 1.6213, 'learning_rate': 0.00019801622785229343, 'epoch': 0.3}\n",
      "{'loss': 1.7456, 'learning_rate': 0.00019798310978638847, 'epoch': 0.3}\n",
      "{'loss': 1.5846, 'learning_rate': 0.00019794999172048354, 'epoch': 0.31}\n",
      "{'loss': 1.6238, 'learning_rate': 0.00019791687365457858, 'epoch': 0.31}\n",
      "{'loss': 1.5579, 'learning_rate': 0.00019788375558867362, 'epoch': 0.32}\n",
      "{'loss': 1.3431, 'learning_rate': 0.0001978506375227687, 'epoch': 0.32}\n",
      "{'loss': 1.5044, 'learning_rate': 0.00019781751945686373, 'epoch': 0.33}\n",
      "{'loss': 1.7331, 'learning_rate': 0.00019778440139095878, 'epoch': 0.33}\n",
      "{'loss': 1.5984, 'learning_rate': 0.00019775128332505382, 'epoch': 0.34}\n",
      "{'loss': 1.4185, 'learning_rate': 0.0001977181652591489, 'epoch': 0.34}\n",
      "{'loss': 1.6116, 'learning_rate': 0.00019768504719324393, 'epoch': 0.35}\n",
      "{'loss': 1.5651, 'learning_rate': 0.00019765192912733897, 'epoch': 0.35}\n",
      "{'loss': 1.5123, 'learning_rate': 0.00019761881106143401, 'epoch': 0.36}\n",
      "{'loss': 1.515, 'learning_rate': 0.00019758569299552906, 'epoch': 0.36}\n",
      "{'loss': 1.4488, 'learning_rate': 0.0001975525749296241, 'epoch': 0.37}\n",
      "{'loss': 1.5806, 'learning_rate': 0.00019751945686371917, 'epoch': 0.37}\n",
      "{'loss': 1.496, 'learning_rate': 0.0001974863387978142, 'epoch': 0.38}\n",
      "{'loss': 1.4304, 'learning_rate': 0.00019745322073190925, 'epoch': 0.38}\n",
      "{'loss': 1.5275, 'learning_rate': 0.00019742010266600432, 'epoch': 0.39}\n",
      "{'loss': 1.3477, 'learning_rate': 0.00019738698460009937, 'epoch': 0.39}\n",
      "{'loss': 1.4433, 'learning_rate': 0.0001973538665341944, 'epoch': 0.4}\n",
      "{'loss': 1.5297, 'learning_rate': 0.00019732074846828945, 'epoch': 0.4}\n",
      "{'loss': 1.4141, 'learning_rate': 0.00019728763040238452, 'epoch': 0.41}\n",
      "{'loss': 1.5892, 'learning_rate': 0.00019725451233647956, 'epoch': 0.41}\n",
      "{'loss': 1.4115, 'learning_rate': 0.0001972213942705746, 'epoch': 0.42}\n",
      "{'loss': 1.4054, 'learning_rate': 0.00019718827620466967, 'epoch': 0.42}\n",
      "{'loss': 1.5498, 'learning_rate': 0.00019715515813876472, 'epoch': 0.43}\n",
      "{'loss': 1.3422, 'learning_rate': 0.00019712204007285976, 'epoch': 0.43}\n",
      "{'loss': 1.374, 'learning_rate': 0.0001970889220069548, 'epoch': 0.44}\n",
      "{'loss': 1.3852, 'learning_rate': 0.00019705580394104984, 'epoch': 0.44}\n",
      "{'loss': 1.4295, 'learning_rate': 0.00019702268587514489, 'epoch': 0.45}\n",
      "{'loss': 1.6096, 'learning_rate': 0.00019698956780923993, 'epoch': 0.45}\n",
      "{'loss': 1.4043, 'learning_rate': 0.000196956449743335, 'epoch': 0.46}\n",
      "{'loss': 1.4352, 'learning_rate': 0.00019692333167743004, 'epoch': 0.46}\n",
      "{'loss': 1.5063, 'learning_rate': 0.00019689021361152508, 'epoch': 0.47}\n",
      "{'loss': 1.4766, 'learning_rate': 0.00019685709554562015, 'epoch': 0.47}\n",
      "{'loss': 1.38, 'learning_rate': 0.0001968239774797152, 'epoch': 0.48}\n",
      "{'loss': 1.5947, 'learning_rate': 0.00019679085941381024, 'epoch': 0.48}\n",
      "{'loss': 1.533, 'learning_rate': 0.0001967577413479053, 'epoch': 0.49}\n",
      "{'loss': 1.5268, 'learning_rate': 0.00019672462328200035, 'epoch': 0.49}\n",
      "{'loss': 1.3566, 'learning_rate': 0.0001966915052160954, 'epoch': 0.5}\n",
      "{'loss': 1.4304, 'learning_rate': 0.00019665838715019046, 'epoch': 0.5}\n",
      "{'loss': 1.2866, 'learning_rate': 0.0001966252690842855, 'epoch': 0.51}\n",
      "{'loss': 1.1744, 'learning_rate': 0.00019659215101838054, 'epoch': 0.51}\n",
      "{'loss': 1.383, 'learning_rate': 0.0001965590329524756, 'epoch': 0.52}\n",
      "{'loss': 1.3929, 'learning_rate': 0.00019652591488657063, 'epoch': 0.52}\n",
      "{'loss': 1.3647, 'learning_rate': 0.00019649279682066567, 'epoch': 0.53}\n",
      "{'loss': 1.5516, 'learning_rate': 0.00019645967875476071, 'epoch': 0.53}\n",
      "{'loss': 1.3219, 'learning_rate': 0.00019642656068885578, 'epoch': 0.54}\n",
      "{'loss': 1.2026, 'learning_rate': 0.00019639344262295083, 'epoch': 0.54}\n",
      "{'loss': 1.35, 'learning_rate': 0.00019636032455704587, 'epoch': 0.55}\n",
      "{'loss': 1.3991, 'learning_rate': 0.00019632720649114094, 'epoch': 0.55}\n",
      "{'loss': 1.3068, 'learning_rate': 0.00019629408842523598, 'epoch': 0.56}\n",
      "{'loss': 1.3843, 'learning_rate': 0.00019626097035933102, 'epoch': 0.56}\n",
      "{'loss': 1.4914, 'learning_rate': 0.0001962278522934261, 'epoch': 0.57}\n",
      "{'loss': 1.3622, 'learning_rate': 0.00019619473422752113, 'epoch': 0.57}\n",
      "{'loss': 1.3702, 'learning_rate': 0.00019616161616161618, 'epoch': 0.58}\n",
      "{'loss': 1.26, 'learning_rate': 0.00019612849809571122, 'epoch': 0.58}\n",
      "{'loss': 1.3406, 'learning_rate': 0.0001960953800298063, 'epoch': 0.59}\n",
      "{'loss': 1.3857, 'learning_rate': 0.00019606226196390133, 'epoch': 0.59}\n",
      "{'loss': 1.2296, 'learning_rate': 0.00019602914389799635, 'epoch': 0.6}\n",
      "{'loss': 1.3274, 'learning_rate': 0.00019599602583209142, 'epoch': 0.6}\n",
      "{'loss': 1.2797, 'learning_rate': 0.00019596290776618646, 'epoch': 0.61}\n",
      "{'loss': 1.2528, 'learning_rate': 0.0001959297897002815, 'epoch': 0.61}\n",
      "{'loss': 1.4504, 'learning_rate': 0.00019589667163437657, 'epoch': 0.62}\n",
      "{'loss': 1.4582, 'learning_rate': 0.0001958635535684716, 'epoch': 0.62}\n",
      "{'loss': 1.5374, 'learning_rate': 0.00019583043550256665, 'epoch': 0.63}\n",
      "{'loss': 1.3178, 'learning_rate': 0.0001957973174366617, 'epoch': 0.63}\n",
      "{'loss': 1.2624, 'learning_rate': 0.00019576419937075677, 'epoch': 0.64}\n",
      "{'loss': 1.2039, 'learning_rate': 0.0001957310813048518, 'epoch': 0.64}\n",
      "{'loss': 1.3754, 'learning_rate': 0.00019569796323894685, 'epoch': 0.65}\n",
      "{'loss': 1.1588, 'learning_rate': 0.00019566484517304192, 'epoch': 0.65}\n",
      "{'loss': 1.2543, 'learning_rate': 0.00019563172710713696, 'epoch': 0.66}\n",
      "{'loss': 1.2217, 'learning_rate': 0.000195598609041232, 'epoch': 0.66}\n",
      "{'loss': 1.4244, 'learning_rate': 0.00019556549097532705, 'epoch': 0.67}\n",
      "{'loss': 1.1572, 'learning_rate': 0.0001955323729094221, 'epoch': 0.67}\n",
      "{'loss': 1.151, 'learning_rate': 0.00019549925484351713, 'epoch': 0.68}\n",
      "{'loss': 1.2063, 'learning_rate': 0.0001954661367776122, 'epoch': 0.68}\n",
      "{'loss': 1.322, 'learning_rate': 0.00019543301871170724, 'epoch': 0.69}\n",
      "{'loss': 1.2392, 'learning_rate': 0.00019539990064580229, 'epoch': 0.69}\n",
      "{'loss': 1.2619, 'learning_rate': 0.00019536678257989733, 'epoch': 0.7}\n",
      "{'loss': 1.169, 'learning_rate': 0.0001953336645139924, 'epoch': 0.7}\n",
      "{'loss': 1.3196, 'learning_rate': 0.00019530054644808744, 'epoch': 0.71}\n",
      "{'loss': 1.2206, 'learning_rate': 0.00019526742838218248, 'epoch': 0.71}\n",
      "{'loss': 1.3428, 'learning_rate': 0.00019523431031627755, 'epoch': 0.72}\n",
      "{'loss': 1.3536, 'learning_rate': 0.0001952011922503726, 'epoch': 0.72}\n",
      "{'loss': 1.3433, 'learning_rate': 0.00019516807418446764, 'epoch': 0.73}\n",
      "{'loss': 1.3427, 'learning_rate': 0.0001951349561185627, 'epoch': 0.73}\n",
      "{'loss': 1.0274, 'learning_rate': 0.00019510183805265775, 'epoch': 0.74}\n",
      "{'loss': 1.4631, 'learning_rate': 0.0001950687199867528, 'epoch': 0.74}\n",
      "{'loss': 1.3744, 'learning_rate': 0.00019503560192084783, 'epoch': 0.75}\n",
      "{'loss': 1.2899, 'learning_rate': 0.00019500248385494288, 'epoch': 0.75}\n",
      "{'loss': 1.3239, 'learning_rate': 0.00019496936578903792, 'epoch': 0.76}\n",
      "{'loss': 1.4824, 'learning_rate': 0.00019493624772313296, 'epoch': 0.76}\n",
      "{'loss': 1.2687, 'learning_rate': 0.00019490312965722803, 'epoch': 0.77}\n",
      "{'loss': 1.1795, 'learning_rate': 0.00019487001159132307, 'epoch': 0.77}\n",
      "{'loss': 1.3559, 'learning_rate': 0.00019483689352541811, 'epoch': 0.77}\n",
      "{'loss': 1.2845, 'learning_rate': 0.00019480377545951318, 'epoch': 0.78}\n",
      "{'loss': 1.2345, 'learning_rate': 0.00019477065739360823, 'epoch': 0.78}\n",
      "{'loss': 1.2831, 'learning_rate': 0.00019473753932770327, 'epoch': 0.79}\n",
      "{'loss': 1.1885, 'learning_rate': 0.00019470442126179834, 'epoch': 0.79}\n",
      "{'loss': 1.2245, 'learning_rate': 0.00019467130319589338, 'epoch': 0.8}\n",
      "{'loss': 1.2071, 'learning_rate': 0.00019463818512998842, 'epoch': 0.8}\n",
      "{'loss': 1.2159, 'learning_rate': 0.00019460506706408346, 'epoch': 0.81}\n",
      "{'loss': 1.24, 'learning_rate': 0.00019457194899817853, 'epoch': 0.81}\n",
      "{'loss': 1.1513, 'learning_rate': 0.00019453883093227358, 'epoch': 0.82}\n",
      "{'loss': 1.1037, 'learning_rate': 0.00019450571286636862, 'epoch': 0.82}\n",
      "{'loss': 1.4713, 'learning_rate': 0.00019447259480046366, 'epoch': 0.83}\n",
      "{'loss': 1.2016, 'learning_rate': 0.0001944394767345587, 'epoch': 0.83}\n",
      "{'loss': 1.3746, 'learning_rate': 0.00019440635866865375, 'epoch': 0.84}\n",
      "{'loss': 1.2521, 'learning_rate': 0.00019437324060274882, 'epoch': 0.84}\n",
      "{'loss': 1.1037, 'learning_rate': 0.00019434012253684386, 'epoch': 0.85}\n",
      "{'loss': 1.2359, 'learning_rate': 0.0001943070044709389, 'epoch': 0.85}\n",
      "{'loss': 1.2075, 'learning_rate': 0.00019427388640503394, 'epoch': 0.86}\n",
      "{'loss': 1.1748, 'learning_rate': 0.000194240768339129, 'epoch': 0.86}\n",
      "{'loss': 1.3085, 'learning_rate': 0.00019420765027322405, 'epoch': 0.87}\n",
      "{'loss': 1.0585, 'learning_rate': 0.0001941745322073191, 'epoch': 0.87}\n",
      "{'loss': 1.1526, 'learning_rate': 0.00019414141414141417, 'epoch': 0.88}\n",
      "{'loss': 0.9823, 'learning_rate': 0.0001941082960755092, 'epoch': 0.88}\n",
      "{'loss': 1.305, 'learning_rate': 0.00019407517800960425, 'epoch': 0.89}\n",
      "{'loss': 1.1741, 'learning_rate': 0.0001940420599436993, 'epoch': 0.89}\n",
      "{'loss': 1.0672, 'learning_rate': 0.00019400894187779434, 'epoch': 0.9}\n",
      "{'loss': 1.3027, 'learning_rate': 0.00019397582381188938, 'epoch': 0.9}\n",
      "{'loss': 1.3173, 'learning_rate': 0.00019394270574598445, 'epoch': 0.91}\n",
      "{'loss': 1.1165, 'learning_rate': 0.0001939095876800795, 'epoch': 0.91}\n",
      "{'loss': 1.217, 'learning_rate': 0.00019387646961417453, 'epoch': 0.92}\n",
      "{'loss': 1.114, 'learning_rate': 0.00019384335154826957, 'epoch': 0.92}\n",
      "{'loss': 1.2485, 'learning_rate': 0.00019381023348236464, 'epoch': 0.93}\n",
      "{'loss': 1.2596, 'learning_rate': 0.00019377711541645969, 'epoch': 0.93}\n",
      "{'loss': 1.343, 'learning_rate': 0.00019374399735055473, 'epoch': 0.94}\n",
      "{'loss': 1.1426, 'learning_rate': 0.0001937108792846498, 'epoch': 0.94}\n",
      "{'loss': 1.2008, 'learning_rate': 0.00019367776121874484, 'epoch': 0.95}\n",
      "{'loss': 1.0076, 'learning_rate': 0.00019364464315283988, 'epoch': 0.95}\n",
      "{'loss': 1.2351, 'learning_rate': 0.00019361152508693495, 'epoch': 0.96}\n",
      "{'loss': 1.2004, 'learning_rate': 0.00019357840702103, 'epoch': 0.96}\n",
      "{'loss': 1.269, 'learning_rate': 0.00019354528895512504, 'epoch': 0.97}\n",
      "{'loss': 1.1784, 'learning_rate': 0.00019351217088922008, 'epoch': 0.97}\n",
      "{'loss': 1.1018, 'learning_rate': 0.00019347905282331512, 'epoch': 0.98}\n",
      "{'loss': 1.118, 'learning_rate': 0.00019344593475741016, 'epoch': 0.98}\n",
      "{'loss': 1.2418, 'learning_rate': 0.0001934128166915052, 'epoch': 0.99}\n",
      "{'loss': 1.1533, 'learning_rate': 0.00019337969862560028, 'epoch': 0.99}\n",
      "{'loss': 1.2244, 'learning_rate': 0.00019334658055969532, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11363\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018503189086914062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1421,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a39318fd204d73b50a06b7e25c939c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../102722run\\checkpoint-2013\n",
      "Configuration saved in ../102722run\\checkpoint-2013\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.159117341041565, 'eval_accuracy': 0.7056235149168354, 'eval_runtime': 103.8891, 'eval_samples_per_second': 109.376, 'eval_steps_per_second': 13.678, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../102722run\\checkpoint-2013\\pytorch_model.bin\n",
      "Feature extractor saved in ../102722run\\checkpoint-2013\\preprocessor_config.json\n",
      "Feature extractor saved in ../102722run\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0039, 'learning_rate': 0.00019331346249379036, 'epoch': 1.0}\n",
      "{'loss': 1.0572, 'learning_rate': 0.00019328034442788543, 'epoch': 1.01}\n",
      "{'loss': 1.0777, 'learning_rate': 0.00019324722636198047, 'epoch': 1.01}\n",
      "{'loss': 1.1844, 'learning_rate': 0.00019321410829607551, 'epoch': 1.02}\n",
      "{'loss': 0.8593, 'learning_rate': 0.00019318099023017058, 'epoch': 1.02}\n",
      "{'loss': 0.9875, 'learning_rate': 0.00019314787216426563, 'epoch': 1.03}\n",
      "{'loss': 1.1458, 'learning_rate': 0.00019311475409836067, 'epoch': 1.03}\n",
      "{'loss': 1.1599, 'learning_rate': 0.0001930816360324557, 'epoch': 1.04}\n",
      "{'loss': 0.9967, 'learning_rate': 0.00019304851796655078, 'epoch': 1.04}\n",
      "{'loss': 1.1294, 'learning_rate': 0.00019301539990064582, 'epoch': 1.05}\n",
      "{'loss': 1.0354, 'learning_rate': 0.00019298228183474086, 'epoch': 1.05}\n",
      "{'loss': 1.2394, 'learning_rate': 0.0001929491637688359, 'epoch': 1.06}\n",
      "{'loss': 0.9632, 'learning_rate': 0.00019291604570293095, 'epoch': 1.06}\n",
      "{'loss': 1.1097, 'learning_rate': 0.000192882927637026, 'epoch': 1.07}\n",
      "{'loss': 1.0521, 'learning_rate': 0.00019284980957112106, 'epoch': 1.07}\n",
      "{'loss': 1.1586, 'learning_rate': 0.0001928166915052161, 'epoch': 1.08}\n",
      "{'loss': 1.0772, 'learning_rate': 0.00019278357343931115, 'epoch': 1.08}\n",
      "{'loss': 1.0151, 'learning_rate': 0.0001927504553734062, 'epoch': 1.09}\n",
      "{'loss': 0.9545, 'learning_rate': 0.00019271733730750126, 'epoch': 1.09}\n",
      "{'loss': 0.9572, 'learning_rate': 0.0001926842192415963, 'epoch': 1.1}\n",
      "{'loss': 1.203, 'learning_rate': 0.00019265110117569134, 'epoch': 1.1}\n",
      "{'loss': 1.0456, 'learning_rate': 0.0001926179831097864, 'epoch': 1.11}\n",
      "{'loss': 0.9457, 'learning_rate': 0.00019258486504388145, 'epoch': 1.11}\n",
      "{'loss': 1.222, 'learning_rate': 0.0001925517469779765, 'epoch': 1.12}\n",
      "{'loss': 1.2335, 'learning_rate': 0.00019251862891207157, 'epoch': 1.12}\n",
      "{'loss': 1.0825, 'learning_rate': 0.00019248551084616658, 'epoch': 1.13}\n",
      "{'loss': 1.1801, 'learning_rate': 0.00019245239278026162, 'epoch': 1.13}\n",
      "{'loss': 1.0317, 'learning_rate': 0.0001924192747143567, 'epoch': 1.14}\n",
      "{'loss': 0.9891, 'learning_rate': 0.00019238615664845174, 'epoch': 1.14}\n",
      "{'loss': 0.9994, 'learning_rate': 0.00019235303858254678, 'epoch': 1.15}\n",
      "{'loss': 1.006, 'learning_rate': 0.00019231992051664182, 'epoch': 1.15}\n",
      "{'loss': 1.1163, 'learning_rate': 0.0001922868024507369, 'epoch': 1.16}\n",
      "{'loss': 1.024, 'learning_rate': 0.00019225368438483193, 'epoch': 1.16}\n",
      "{'loss': 1.1374, 'learning_rate': 0.00019222056631892697, 'epoch': 1.17}\n",
      "{'loss': 1.162, 'learning_rate': 0.00019218744825302204, 'epoch': 1.17}\n",
      "{'loss': 1.1692, 'learning_rate': 0.00019215433018711709, 'epoch': 1.18}\n",
      "{'loss': 1.1384, 'learning_rate': 0.00019212121212121213, 'epoch': 1.18}\n",
      "{'loss': 0.9955, 'learning_rate': 0.0001920880940553072, 'epoch': 1.19}\n",
      "{'loss': 1.0567, 'learning_rate': 0.00019205497598940224, 'epoch': 1.19}\n",
      "{'loss': 1.1961, 'learning_rate': 0.00019202185792349728, 'epoch': 1.2}\n",
      "{'loss': 0.9558, 'learning_rate': 0.00019198873985759232, 'epoch': 1.2}\n",
      "{'loss': 1.0102, 'learning_rate': 0.00019195562179168737, 'epoch': 1.21}\n",
      "{'loss': 1.0424, 'learning_rate': 0.0001919225037257824, 'epoch': 1.21}\n",
      "{'loss': 0.9886, 'learning_rate': 0.00019188938565987745, 'epoch': 1.22}\n",
      "{'loss': 0.9563, 'learning_rate': 0.00019185626759397252, 'epoch': 1.22}\n",
      "{'loss': 1.099, 'learning_rate': 0.00019182314952806756, 'epoch': 1.23}\n",
      "{'loss': 0.9979, 'learning_rate': 0.0001917900314621626, 'epoch': 1.23}\n",
      "{'loss': 1.0188, 'learning_rate': 0.00019175691339625768, 'epoch': 1.24}\n",
      "{'loss': 1.0057, 'learning_rate': 0.00019172379533035272, 'epoch': 1.24}\n",
      "{'loss': 1.0341, 'learning_rate': 0.00019169067726444776, 'epoch': 1.25}\n",
      "{'loss': 1.0881, 'learning_rate': 0.00019165755919854283, 'epoch': 1.25}\n",
      "{'loss': 1.0098, 'learning_rate': 0.00019162444113263787, 'epoch': 1.26}\n",
      "{'loss': 1.0903, 'learning_rate': 0.00019159132306673291, 'epoch': 1.26}\n",
      "{'loss': 0.9918, 'learning_rate': 0.00019155820500082796, 'epoch': 1.27}\n",
      "{'loss': 1.2763, 'learning_rate': 0.00019152508693492303, 'epoch': 1.27}\n",
      "{'loss': 1.0409, 'learning_rate': 0.00019149528067560856, 'epoch': 1.28}\n",
      "{'loss': 1.2197, 'learning_rate': 0.0001914621626097036, 'epoch': 1.28}\n",
      "{'loss': 1.1053, 'learning_rate': 0.00019142904454379865, 'epoch': 1.29}\n",
      "{'loss': 1.1712, 'learning_rate': 0.00019139592647789372, 'epoch': 1.29}\n",
      "{'loss': 1.125, 'learning_rate': 0.00019136280841198876, 'epoch': 1.3}\n",
      "{'loss': 0.9982, 'learning_rate': 0.0001913296903460838, 'epoch': 1.3}\n",
      "{'loss': 1.1101, 'learning_rate': 0.00019129657228017885, 'epoch': 1.31}\n",
      "{'loss': 1.0296, 'learning_rate': 0.0001912634542142739, 'epoch': 1.31}\n",
      "{'loss': 0.9675, 'learning_rate': 0.00019123033614836893, 'epoch': 1.32}\n",
      "{'loss': 1.175, 'learning_rate': 0.000191197218082464, 'epoch': 1.32}\n",
      "{'loss': 1.0503, 'learning_rate': 0.00019116410001655904, 'epoch': 1.33}\n",
      "{'loss': 1.0122, 'learning_rate': 0.00019113098195065408, 'epoch': 1.33}\n",
      "{'loss': 1.0205, 'learning_rate': 0.00019109786388474913, 'epoch': 1.34}\n",
      "{'loss': 1.0946, 'learning_rate': 0.0001910647458188442, 'epoch': 1.34}\n",
      "{'loss': 0.8587, 'learning_rate': 0.00019103162775293924, 'epoch': 1.35}\n",
      "{'loss': 1.0705, 'learning_rate': 0.00019099850968703428, 'epoch': 1.35}\n",
      "{'loss': 1.0939, 'learning_rate': 0.00019096539162112935, 'epoch': 1.36}\n",
      "{'loss': 1.1197, 'learning_rate': 0.0001909322735552244, 'epoch': 1.36}\n",
      "{'loss': 0.9808, 'learning_rate': 0.00019089915548931943, 'epoch': 1.37}\n",
      "{'loss': 1.1814, 'learning_rate': 0.00019086934923000497, 'epoch': 1.37}\n",
      "{'loss': 1.2077, 'learning_rate': 0.00019083623116410004, 'epoch': 1.38}\n",
      "{'loss': 0.9839, 'learning_rate': 0.00019080311309819508, 'epoch': 1.38}\n",
      "{'loss': 0.915, 'learning_rate': 0.00019076999503229013, 'epoch': 1.39}\n",
      "{'loss': 1.1224, 'learning_rate': 0.00019073687696638517, 'epoch': 1.39}\n",
      "{'loss': 1.0126, 'learning_rate': 0.0001907037589004802, 'epoch': 1.4}\n",
      "{'loss': 1.0232, 'learning_rate': 0.00019067064083457525, 'epoch': 1.4}\n",
      "{'loss': 0.9066, 'learning_rate': 0.00019063752276867032, 'epoch': 1.41}\n",
      "{'loss': 1.1237, 'learning_rate': 0.00019060440470276537, 'epoch': 1.41}\n",
      "{'loss': 1.1123, 'learning_rate': 0.0001905712866368604, 'epoch': 1.42}\n",
      "{'loss': 1.0868, 'learning_rate': 0.00019053816857095545, 'epoch': 1.42}\n",
      "{'loss': 1.1468, 'learning_rate': 0.00019050505050505052, 'epoch': 1.43}\n",
      "{'loss': 0.9257, 'learning_rate': 0.00019047193243914556, 'epoch': 1.43}\n",
      "{'loss': 0.9655, 'learning_rate': 0.0001904388143732406, 'epoch': 1.44}\n",
      "{'loss': 0.9762, 'learning_rate': 0.00019040569630733567, 'epoch': 1.44}\n",
      "{'loss': 0.9373, 'learning_rate': 0.00019037257824143072, 'epoch': 1.45}\n",
      "{'loss': 0.9793, 'learning_rate': 0.00019033946017552576, 'epoch': 1.45}\n",
      "{'loss': 0.9703, 'learning_rate': 0.00019030634210962083, 'epoch': 1.46}\n",
      "{'loss': 1.0601, 'learning_rate': 0.00019027322404371587, 'epoch': 1.46}\n",
      "{'loss': 1.017, 'learning_rate': 0.0001902401059778109, 'epoch': 1.47}\n",
      "{'loss': 0.981, 'learning_rate': 0.00019020698791190596, 'epoch': 1.47}\n",
      "{'loss': 1.0583, 'learning_rate': 0.000190173869846001, 'epoch': 1.48}\n",
      "{'loss': 0.9777, 'learning_rate': 0.00019014075178009604, 'epoch': 1.48}\n",
      "{'loss': 1.0301, 'learning_rate': 0.00019010763371419108, 'epoch': 1.49}\n",
      "{'loss': 1.1482, 'learning_rate': 0.00019007451564828615, 'epoch': 1.49}\n",
      "{'loss': 1.195, 'learning_rate': 0.0001900413975823812, 'epoch': 1.5}\n",
      "{'loss': 0.9875, 'learning_rate': 0.00019000827951647624, 'epoch': 1.5}\n",
      "{'loss': 0.9995, 'learning_rate': 0.0001899751614505713, 'epoch': 1.51}\n",
      "{'loss': 0.8939, 'learning_rate': 0.00018994204338466635, 'epoch': 1.51}\n",
      "{'loss': 1.0482, 'learning_rate': 0.0001899089253187614, 'epoch': 1.52}\n",
      "{'loss': 1.1673, 'learning_rate': 0.00018987580725285646, 'epoch': 1.52}\n",
      "{'loss': 1.0142, 'learning_rate': 0.0001898426891869515, 'epoch': 1.53}\n",
      "{'loss': 0.9871, 'learning_rate': 0.00018980957112104654, 'epoch': 1.53}\n",
      "{'loss': 1.1044, 'learning_rate': 0.0001897764530551416, 'epoch': 1.54}\n",
      "{'loss': 1.1671, 'learning_rate': 0.00018974333498923666, 'epoch': 1.54}\n",
      "{'loss': 1.0089, 'learning_rate': 0.00018971021692333167, 'epoch': 1.54}\n",
      "{'loss': 0.9944, 'learning_rate': 0.00018967709885742671, 'epoch': 1.55}\n",
      "{'loss': 0.8488, 'learning_rate': 0.00018964398079152178, 'epoch': 1.55}\n",
      "{'loss': 1.0347, 'learning_rate': 0.00018961086272561683, 'epoch': 1.56}\n",
      "{'loss': 1.0001, 'learning_rate': 0.00018957774465971187, 'epoch': 1.56}\n",
      "{'loss': 0.952, 'learning_rate': 0.00018954462659380694, 'epoch': 1.57}\n",
      "{'loss': 1.0965, 'learning_rate': 0.00018951150852790198, 'epoch': 1.57}\n",
      "{'loss': 1.0518, 'learning_rate': 0.00018947839046199702, 'epoch': 1.58}\n",
      "{'loss': 1.0398, 'learning_rate': 0.0001894452723960921, 'epoch': 1.58}\n",
      "{'loss': 1.016, 'learning_rate': 0.00018941215433018713, 'epoch': 1.59}\n",
      "{'loss': 1.0568, 'learning_rate': 0.00018937903626428218, 'epoch': 1.59}\n",
      "{'loss': 1.2561, 'learning_rate': 0.00018934591819837722, 'epoch': 1.6}\n",
      "{'loss': 1.1506, 'learning_rate': 0.0001893128001324723, 'epoch': 1.6}\n",
      "{'loss': 1.1752, 'learning_rate': 0.00018927968206656733, 'epoch': 1.61}\n",
      "{'loss': 0.9377, 'learning_rate': 0.00018924656400066237, 'epoch': 1.61}\n",
      "{'loss': 0.8859, 'learning_rate': 0.00018921344593475742, 'epoch': 1.62}\n",
      "{'loss': 0.8867, 'learning_rate': 0.00018918032786885246, 'epoch': 1.62}\n",
      "{'loss': 1.0462, 'learning_rate': 0.0001891472098029475, 'epoch': 1.63}\n",
      "{'loss': 1.1062, 'learning_rate': 0.00018911409173704257, 'epoch': 1.63}\n",
      "{'loss': 0.9597, 'learning_rate': 0.0001890809736711376, 'epoch': 1.64}\n",
      "{'loss': 0.9444, 'learning_rate': 0.00018904785560523265, 'epoch': 1.64}\n",
      "{'loss': 0.9319, 'learning_rate': 0.0001890147375393277, 'epoch': 1.65}\n",
      "{'loss': 1.0248, 'learning_rate': 0.00018898161947342277, 'epoch': 1.65}\n",
      "{'loss': 1.0281, 'learning_rate': 0.0001889485014075178, 'epoch': 1.66}\n",
      "{'loss': 1.0828, 'learning_rate': 0.00018891538334161285, 'epoch': 1.66}\n",
      "{'loss': 1.0033, 'learning_rate': 0.00018888226527570792, 'epoch': 1.67}\n",
      "{'loss': 0.9785, 'learning_rate': 0.00018884914720980296, 'epoch': 1.67}\n",
      "{'loss': 1.0175, 'learning_rate': 0.000188816029143898, 'epoch': 1.68}\n",
      "{'loss': 1.1449, 'learning_rate': 0.00018878291107799307, 'epoch': 1.68}\n",
      "{'loss': 1.0625, 'learning_rate': 0.00018874979301208812, 'epoch': 1.69}\n",
      "{'loss': 1.1021, 'learning_rate': 0.00018871667494618316, 'epoch': 1.69}\n",
      "{'loss': 1.1591, 'learning_rate': 0.0001886835568802782, 'epoch': 1.7}\n",
      "{'loss': 1.0258, 'learning_rate': 0.00018865043881437324, 'epoch': 1.7}\n",
      "{'loss': 1.0351, 'learning_rate': 0.0001886206325550588, 'epoch': 1.71}\n",
      "{'loss': 1.0058, 'learning_rate': 0.00018858751448915385, 'epoch': 1.71}\n",
      "{'loss': 1.0987, 'learning_rate': 0.0001885543964232489, 'epoch': 1.72}\n",
      "{'loss': 1.0835, 'learning_rate': 0.00018852127835734394, 'epoch': 1.72}\n",
      "{'loss': 0.9349, 'learning_rate': 0.00018848816029143898, 'epoch': 1.73}\n",
      "{'loss': 1.0343, 'learning_rate': 0.00018845504222553402, 'epoch': 1.73}\n",
      "{'loss': 0.8327, 'learning_rate': 0.0001884219241596291, 'epoch': 1.74}\n",
      "{'loss': 0.8683, 'learning_rate': 0.00018838880609372413, 'epoch': 1.74}\n",
      "{'loss': 0.9661, 'learning_rate': 0.00018835568802781917, 'epoch': 1.75}\n",
      "{'loss': 0.9092, 'learning_rate': 0.00018832256996191424, 'epoch': 1.75}\n",
      "{'loss': 0.8868, 'learning_rate': 0.00018828945189600929, 'epoch': 1.76}\n",
      "{'loss': 1.0502, 'learning_rate': 0.00018825633383010433, 'epoch': 1.76}\n",
      "{'loss': 1.1777, 'learning_rate': 0.0001882232157641994, 'epoch': 1.77}\n",
      "{'loss': 0.9301, 'learning_rate': 0.00018819009769829444, 'epoch': 1.77}\n",
      "{'loss': 1.0395, 'learning_rate': 0.00018815697963238948, 'epoch': 1.78}\n",
      "{'loss': 1.0473, 'learning_rate': 0.00018812386156648453, 'epoch': 1.78}\n",
      "{'loss': 1.0845, 'learning_rate': 0.00018809074350057957, 'epoch': 1.79}\n",
      "{'loss': 0.8032, 'learning_rate': 0.0001880576254346746, 'epoch': 1.79}\n",
      "{'loss': 1.0221, 'learning_rate': 0.00018802450736876965, 'epoch': 1.8}\n",
      "{'loss': 0.9544, 'learning_rate': 0.00018799138930286472, 'epoch': 1.8}\n",
      "{'loss': 0.9779, 'learning_rate': 0.00018795827123695976, 'epoch': 1.81}\n",
      "{'loss': 1.1512, 'learning_rate': 0.0001879251531710548, 'epoch': 1.81}\n",
      "{'loss': 0.9912, 'learning_rate': 0.00018789203510514988, 'epoch': 1.82}\n",
      "{'loss': 0.8825, 'learning_rate': 0.00018785891703924492, 'epoch': 1.82}\n",
      "{'loss': 0.9902, 'learning_rate': 0.00018782579897333996, 'epoch': 1.83}\n",
      "{'loss': 1.0991, 'learning_rate': 0.00018779268090743503, 'epoch': 1.83}\n",
      "{'loss': 1.0727, 'learning_rate': 0.00018775956284153007, 'epoch': 1.84}\n",
      "{'loss': 0.9366, 'learning_rate': 0.00018772644477562511, 'epoch': 1.84}\n",
      "{'loss': 1.0921, 'learning_rate': 0.00018769332670972016, 'epoch': 1.85}\n",
      "{'loss': 1.0451, 'learning_rate': 0.00018766020864381523, 'epoch': 1.85}\n",
      "{'loss': 1.2603, 'learning_rate': 0.00018762709057791027, 'epoch': 1.86}\n",
      "{'loss': 1.0008, 'learning_rate': 0.0001875939725120053, 'epoch': 1.86}\n",
      "{'loss': 0.9384, 'learning_rate': 0.00018756085444610035, 'epoch': 1.87}\n",
      "{'loss': 1.0207, 'learning_rate': 0.0001875277363801954, 'epoch': 1.87}\n",
      "{'loss': 0.9524, 'learning_rate': 0.00018749461831429044, 'epoch': 1.88}\n",
      "{'loss': 0.9083, 'learning_rate': 0.0001874615002483855, 'epoch': 1.88}\n",
      "{'loss': 1.0447, 'learning_rate': 0.00018742838218248055, 'epoch': 1.89}\n",
      "{'loss': 0.9731, 'learning_rate': 0.0001873952641165756, 'epoch': 1.89}\n",
      "{'loss': 1.1576, 'learning_rate': 0.00018736214605067063, 'epoch': 1.9}\n",
      "{'loss': 1.1758, 'learning_rate': 0.0001873290279847657, 'epoch': 1.9}\n",
      "{'loss': 1.0142, 'learning_rate': 0.00018729590991886075, 'epoch': 1.91}\n",
      "{'loss': 1.0464, 'learning_rate': 0.0001872627918529558, 'epoch': 1.91}\n",
      "{'loss': 0.7217, 'learning_rate': 0.00018722967378705086, 'epoch': 1.92}\n",
      "{'loss': 1.1508, 'learning_rate': 0.0001871965557211459, 'epoch': 1.92}\n",
      "{'loss': 0.9101, 'learning_rate': 0.00018716343765524094, 'epoch': 1.93}\n",
      "{'loss': 0.9568, 'learning_rate': 0.000187130319589336, 'epoch': 1.93}\n",
      "{'loss': 0.9899, 'learning_rate': 0.00018709720152343105, 'epoch': 1.94}\n",
      "{'loss': 0.9042, 'learning_rate': 0.0001870640834575261, 'epoch': 1.94}\n",
      "{'loss': 1.1062, 'learning_rate': 0.00018703096539162114, 'epoch': 1.95}\n",
      "{'loss': 0.978, 'learning_rate': 0.00018699784732571618, 'epoch': 1.95}\n",
      "{'loss': 1.1775, 'learning_rate': 0.00018696472925981122, 'epoch': 1.96}\n",
      "{'loss': 1.1841, 'learning_rate': 0.00018693161119390627, 'epoch': 1.96}\n",
      "{'loss': 0.9277, 'learning_rate': 0.00018689849312800134, 'epoch': 1.97}\n",
      "{'loss': 0.972, 'learning_rate': 0.00018686537506209638, 'epoch': 1.97}\n",
      "{'loss': 1.1011, 'learning_rate': 0.00018683225699619142, 'epoch': 1.98}\n",
      "{'loss': 1.0179, 'learning_rate': 0.0001867991389302865, 'epoch': 1.98}\n",
      "{'loss': 0.8973, 'learning_rate': 0.00018676602086438153, 'epoch': 1.99}\n",
      "{'loss': 1.0648, 'learning_rate': 0.00018673290279847657, 'epoch': 1.99}\n",
      "{'loss': 1.019, 'learning_rate': 0.00018669978473257164, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11363\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016002178192138672,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1421,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f84621980f84bfa8cda558d5dfd7364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../102722run\\checkpoint-4026\n",
      "Configuration saved in ../102722run\\checkpoint-4026\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0900472402572632, 'eval_accuracy': 0.723664525213412, 'eval_runtime': 105.2453, 'eval_samples_per_second': 107.967, 'eval_steps_per_second': 13.502, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../102722run\\checkpoint-4026\\pytorch_model.bin\n",
      "Feature extractor saved in ../102722run\\checkpoint-4026\\preprocessor_config.json\n",
      "Feature extractor saved in ../102722run\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1292, 'learning_rate': 0.0001866666666666667, 'epoch': 2.0}\n",
      "{'loss': 0.767, 'learning_rate': 0.00018663354860076173, 'epoch': 2.01}\n",
      "{'loss': 0.8348, 'learning_rate': 0.00018660043053485677, 'epoch': 2.01}\n",
      "{'loss': 0.9144, 'learning_rate': 0.0001865673124689518, 'epoch': 2.02}\n",
      "{'loss': 0.7701, 'learning_rate': 0.00018653419440304686, 'epoch': 2.02}\n",
      "{'loss': 0.8194, 'learning_rate': 0.0001865010763371419, 'epoch': 2.03}\n",
      "{'loss': 0.7605, 'learning_rate': 0.00018646795827123697, 'epoch': 2.03}\n",
      "{'loss': 0.742, 'learning_rate': 0.000186434840205332, 'epoch': 2.04}\n",
      "{'loss': 0.8735, 'learning_rate': 0.00018640172213942705, 'epoch': 2.04}\n",
      "{'loss': 0.9402, 'learning_rate': 0.00018636860407352212, 'epoch': 2.05}\n",
      "{'loss': 0.8447, 'learning_rate': 0.00018633548600761716, 'epoch': 2.05}\n",
      "{'loss': 0.8801, 'learning_rate': 0.0001863023679417122, 'epoch': 2.06}\n",
      "{'loss': 0.9024, 'learning_rate': 0.00018626924987580728, 'epoch': 2.06}\n",
      "{'loss': 1.006, 'learning_rate': 0.00018623613180990232, 'epoch': 2.07}\n",
      "{'loss': 0.8791, 'learning_rate': 0.00018620301374399736, 'epoch': 2.07}\n",
      "{'loss': 1.0549, 'learning_rate': 0.0001861698956780924, 'epoch': 2.08}\n",
      "{'loss': 0.826, 'learning_rate': 0.00018613677761218747, 'epoch': 2.08}\n",
      "{'loss': 0.9333, 'learning_rate': 0.00018610365954628251, 'epoch': 2.09}\n",
      "{'loss': 0.866, 'learning_rate': 0.00018607054148037756, 'epoch': 2.09}\n",
      "{'loss': 1.04, 'learning_rate': 0.0001860374234144726, 'epoch': 2.1}\n",
      "{'loss': 0.7735, 'learning_rate': 0.00018600430534856764, 'epoch': 2.1}\n",
      "{'loss': 0.956, 'learning_rate': 0.00018597118728266268, 'epoch': 2.11}\n",
      "{'loss': 0.9878, 'learning_rate': 0.00018593806921675775, 'epoch': 2.11}\n",
      "{'loss': 0.8199, 'learning_rate': 0.0001859049511508528, 'epoch': 2.12}\n",
      "{'loss': 0.6784, 'learning_rate': 0.00018587183308494784, 'epoch': 2.12}\n",
      "{'loss': 0.8935, 'learning_rate': 0.00018583871501904288, 'epoch': 2.13}\n",
      "{'loss': 0.8624, 'learning_rate': 0.00018580559695313795, 'epoch': 2.13}\n",
      "{'loss': 0.9398, 'learning_rate': 0.000185772478887233, 'epoch': 2.14}\n",
      "{'loss': 0.9046, 'learning_rate': 0.00018573936082132803, 'epoch': 2.14}\n",
      "{'loss': 1.0268, 'learning_rate': 0.0001857062427554231, 'epoch': 2.15}\n",
      "{'loss': 0.7887, 'learning_rate': 0.00018567312468951815, 'epoch': 2.15}\n",
      "{'loss': 0.7773, 'learning_rate': 0.0001856400066236132, 'epoch': 2.16}\n",
      "{'loss': 0.9736, 'learning_rate': 0.00018560688855770826, 'epoch': 2.16}\n",
      "{'loss': 0.9713, 'learning_rate': 0.0001855737704918033, 'epoch': 2.17}\n",
      "{'loss': 0.8707, 'learning_rate': 0.00018554065242589834, 'epoch': 2.17}\n",
      "{'loss': 0.7909, 'learning_rate': 0.00018550753435999339, 'epoch': 2.18}\n",
      "{'loss': 0.8199, 'learning_rate': 0.00018547441629408843, 'epoch': 2.18}\n",
      "{'loss': 0.8636, 'learning_rate': 0.00018544129822818347, 'epoch': 2.19}\n",
      "{'loss': 0.8774, 'learning_rate': 0.0001854081801622785, 'epoch': 2.19}\n",
      "{'loss': 0.942, 'learning_rate': 0.00018537506209637358, 'epoch': 2.2}\n",
      "{'loss': 1.0047, 'learning_rate': 0.00018534194403046862, 'epoch': 2.2}\n",
      "{'loss': 1.0122, 'learning_rate': 0.00018530882596456367, 'epoch': 2.21}\n",
      "{'loss': 0.9224, 'learning_rate': 0.00018527570789865874, 'epoch': 2.21}\n",
      "{'loss': 1.0519, 'learning_rate': 0.00018524258983275378, 'epoch': 2.22}\n",
      "{'loss': 0.7831, 'learning_rate': 0.00018520947176684882, 'epoch': 2.22}\n",
      "{'loss': 0.9237, 'learning_rate': 0.0001851763537009439, 'epoch': 2.23}\n",
      "{'loss': 0.9255, 'learning_rate': 0.00018514323563503893, 'epoch': 2.23}\n",
      "{'loss': 0.9148, 'learning_rate': 0.00018511011756913397, 'epoch': 2.24}\n",
      "{'loss': 0.8535, 'learning_rate': 0.00018507699950322902, 'epoch': 2.24}\n",
      "{'loss': 0.9228, 'learning_rate': 0.0001850438814373241, 'epoch': 2.25}\n",
      "{'loss': 0.9669, 'learning_rate': 0.00018501076337141913, 'epoch': 2.25}\n",
      "{'loss': 0.9155, 'learning_rate': 0.00018497764530551417, 'epoch': 2.26}\n",
      "{'loss': 0.8946, 'learning_rate': 0.00018494452723960921, 'epoch': 2.26}\n",
      "{'loss': 0.8593, 'learning_rate': 0.00018491140917370426, 'epoch': 2.27}\n",
      "{'loss': 0.7852, 'learning_rate': 0.0001848782911077993, 'epoch': 2.27}\n",
      "{'loss': 0.7715, 'learning_rate': 0.00018484517304189437, 'epoch': 2.28}\n",
      "{'loss': 0.9436, 'learning_rate': 0.0001848120549759894, 'epoch': 2.28}\n",
      "{'loss': 1.0092, 'learning_rate': 0.00018477893691008445, 'epoch': 2.29}\n",
      "{'loss': 0.9342, 'learning_rate': 0.00018474581884417952, 'epoch': 2.29}\n",
      "{'loss': 1.1234, 'learning_rate': 0.00018471270077827456, 'epoch': 2.3}\n",
      "{'loss': 0.8126, 'learning_rate': 0.0001846795827123696, 'epoch': 2.3}\n",
      "{'loss': 0.8776, 'learning_rate': 0.00018464646464646465, 'epoch': 2.31}\n",
      "{'loss': 0.9417, 'learning_rate': 0.00018461334658055972, 'epoch': 2.31}\n",
      "{'loss': 0.8349, 'learning_rate': 0.00018458022851465476, 'epoch': 2.31}\n",
      "{'loss': 0.8823, 'learning_rate': 0.0001845471104487498, 'epoch': 2.32}\n",
      "{'loss': 0.8432, 'learning_rate': 0.00018451399238284485, 'epoch': 2.32}\n",
      "{'loss': 0.9257, 'learning_rate': 0.0001844808743169399, 'epoch': 2.33}\n",
      "{'loss': 0.9798, 'learning_rate': 0.00018444775625103493, 'epoch': 2.33}\n",
      "{'loss': 0.921, 'learning_rate': 0.00018441463818513, 'epoch': 2.34}\n",
      "{'loss': 0.869, 'learning_rate': 0.00018438152011922504, 'epoch': 2.34}\n",
      "{'loss': 0.8853, 'learning_rate': 0.00018434840205332008, 'epoch': 2.35}\n",
      "{'loss': 0.9114, 'learning_rate': 0.00018431528398741513, 'epoch': 2.35}\n",
      "{'loss': 0.6329, 'learning_rate': 0.0001842821659215102, 'epoch': 2.36}\n",
      "{'loss': 1.0572, 'learning_rate': 0.00018424904785560524, 'epoch': 2.36}\n",
      "{'loss': 0.9802, 'learning_rate': 0.00018421592978970028, 'epoch': 2.37}\n",
      "{'loss': 0.8571, 'learning_rate': 0.00018418281172379535, 'epoch': 2.37}\n",
      "{'loss': 0.8369, 'learning_rate': 0.0001841496936578904, 'epoch': 2.38}\n",
      "{'loss': 0.8467, 'learning_rate': 0.00018411657559198543, 'epoch': 2.38}\n",
      "{'loss': 0.785, 'learning_rate': 0.0001840834575260805, 'epoch': 2.39}\n",
      "{'loss': 1.0154, 'learning_rate': 0.00018405033946017555, 'epoch': 2.39}\n",
      "{'loss': 0.7696, 'learning_rate': 0.0001840172213942706, 'epoch': 2.4}\n",
      "{'loss': 0.9351, 'learning_rate': 0.00018398410332836563, 'epoch': 2.4}\n",
      "{'loss': 1.0626, 'learning_rate': 0.00018395098526246067, 'epoch': 2.41}\n",
      "{'loss': 0.8702, 'learning_rate': 0.00018391786719655572, 'epoch': 2.41}\n",
      "{'loss': 0.9237, 'learning_rate': 0.00018388474913065076, 'epoch': 2.42}\n",
      "{'loss': 1.0243, 'learning_rate': 0.00018385163106474583, 'epoch': 2.42}\n",
      "{'loss': 1.0112, 'learning_rate': 0.00018381851299884087, 'epoch': 2.43}\n",
      "{'loss': 0.8711, 'learning_rate': 0.0001837853949329359, 'epoch': 2.43}\n",
      "{'loss': 0.9405, 'learning_rate': 0.00018375227686703098, 'epoch': 2.44}\n",
      "{'loss': 0.7294, 'learning_rate': 0.00018371915880112602, 'epoch': 2.44}\n",
      "{'loss': 0.9021, 'learning_rate': 0.00018368604073522107, 'epoch': 2.45}\n",
      "{'loss': 0.997, 'learning_rate': 0.00018365292266931614, 'epoch': 2.45}\n",
      "{'loss': 0.8145, 'learning_rate': 0.00018361980460341118, 'epoch': 2.46}\n",
      "{'loss': 0.8461, 'learning_rate': 0.00018358668653750622, 'epoch': 2.46}\n",
      "{'loss': 0.9013, 'learning_rate': 0.0001835535684716013, 'epoch': 2.47}\n",
      "{'loss': 0.9588, 'learning_rate': 0.00018352045040569633, 'epoch': 2.47}\n",
      "{'loss': 0.9323, 'learning_rate': 0.00018348733233979137, 'epoch': 2.48}\n",
      "{'loss': 0.8443, 'learning_rate': 0.00018345421427388642, 'epoch': 2.48}\n",
      "{'loss': 0.86, 'learning_rate': 0.00018342109620798146, 'epoch': 2.49}\n",
      "{'loss': 0.8939, 'learning_rate': 0.0001833879781420765, 'epoch': 2.49}\n",
      "{'loss': 0.8162, 'learning_rate': 0.00018335486007617154, 'epoch': 2.5}\n",
      "{'loss': 0.9498, 'learning_rate': 0.00018332174201026661, 'epoch': 2.5}\n",
      "{'loss': 0.8226, 'learning_rate': 0.00018328862394436166, 'epoch': 2.51}\n",
      "{'loss': 0.7827, 'learning_rate': 0.0001832555058784567, 'epoch': 2.51}\n",
      "{'loss': 1.0231, 'learning_rate': 0.00018322238781255177, 'epoch': 2.52}\n",
      "{'loss': 0.8905, 'learning_rate': 0.0001831892697466468, 'epoch': 2.52}\n",
      "{'loss': 0.8402, 'learning_rate': 0.00018315615168074185, 'epoch': 2.53}\n",
      "{'loss': 1.0638, 'learning_rate': 0.0001831230336148369, 'epoch': 2.53}\n",
      "{'loss': 0.9036, 'learning_rate': 0.00018308991554893196, 'epoch': 2.54}\n",
      "{'loss': 0.8978, 'learning_rate': 0.000183056797483027, 'epoch': 2.54}\n",
      "{'loss': 0.7714, 'learning_rate': 0.00018302367941712205, 'epoch': 2.55}\n",
      "{'loss': 0.8674, 'learning_rate': 0.0001829905613512171, 'epoch': 2.55}\n",
      "{'loss': 0.774, 'learning_rate': 0.00018295744328531213, 'epoch': 2.56}\n",
      "{'loss': 0.9591, 'learning_rate': 0.00018292432521940718, 'epoch': 2.56}\n",
      "{'loss': 0.9862, 'learning_rate': 0.00018289120715350225, 'epoch': 2.57}\n",
      "{'loss': 0.9042, 'learning_rate': 0.0001828580890875973, 'epoch': 2.57}\n",
      "{'loss': 0.9898, 'learning_rate': 0.00018282497102169233, 'epoch': 2.58}\n",
      "{'loss': 0.7193, 'learning_rate': 0.0001827918529557874, 'epoch': 2.58}\n",
      "{'loss': 0.8176, 'learning_rate': 0.00018275873488988244, 'epoch': 2.59}\n",
      "{'loss': 0.8581, 'learning_rate': 0.00018272561682397748, 'epoch': 2.59}\n",
      "{'loss': 0.8967, 'learning_rate': 0.00018269249875807253, 'epoch': 2.6}\n",
      "{'loss': 0.8347, 'learning_rate': 0.0001826593806921676, 'epoch': 2.6}\n",
      "{'loss': 0.809, 'learning_rate': 0.00018262626262626264, 'epoch': 2.61}\n",
      "{'loss': 1.0303, 'learning_rate': 0.00018259314456035768, 'epoch': 2.61}\n",
      "{'loss': 0.7367, 'learning_rate': 0.00018256002649445275, 'epoch': 2.62}\n",
      "{'loss': 1.0071, 'learning_rate': 0.0001825269084285478, 'epoch': 2.62}\n",
      "{'loss': 0.9538, 'learning_rate': 0.00018249379036264283, 'epoch': 2.63}\n",
      "{'loss': 1.1013, 'learning_rate': 0.00018246067229673788, 'epoch': 2.63}\n",
      "{'loss': 0.8957, 'learning_rate': 0.00018242755423083292, 'epoch': 2.64}\n",
      "{'loss': 0.8334, 'learning_rate': 0.00018239443616492796, 'epoch': 2.64}\n",
      "{'loss': 1.0125, 'learning_rate': 0.000182361318099023, 'epoch': 2.65}\n",
      "{'loss': 0.958, 'learning_rate': 0.00018232820003311807, 'epoch': 2.65}\n",
      "{'loss': 0.8479, 'learning_rate': 0.00018229508196721312, 'epoch': 2.66}\n",
      "{'loss': 0.9113, 'learning_rate': 0.00018226196390130816, 'epoch': 2.66}\n",
      "{'loss': 0.893, 'learning_rate': 0.00018222884583540323, 'epoch': 2.67}\n",
      "{'loss': 0.785, 'learning_rate': 0.00018219572776949827, 'epoch': 2.67}\n",
      "{'loss': 1.019, 'learning_rate': 0.0001821626097035933, 'epoch': 2.68}\n",
      "{'loss': 0.9016, 'learning_rate': 0.00018212949163768838, 'epoch': 2.68}\n",
      "{'loss': 0.8743, 'learning_rate': 0.00018209637357178342, 'epoch': 2.69}\n",
      "{'loss': 0.8906, 'learning_rate': 0.00018206325550587847, 'epoch': 2.69}\n",
      "{'loss': 0.8813, 'learning_rate': 0.00018203013743997354, 'epoch': 2.7}\n",
      "{'loss': 1.025, 'learning_rate': 0.00018199701937406858, 'epoch': 2.7}\n",
      "{'loss': 0.8402, 'learning_rate': 0.00018196390130816362, 'epoch': 2.71}\n",
      "{'loss': 0.8219, 'learning_rate': 0.00018193078324225866, 'epoch': 2.71}\n",
      "{'loss': 0.8702, 'learning_rate': 0.0001818976651763537, 'epoch': 2.72}\n",
      "{'loss': 0.9461, 'learning_rate': 0.00018186454711044875, 'epoch': 2.72}\n",
      "{'loss': 0.9113, 'learning_rate': 0.0001818314290445438, 'epoch': 2.73}\n",
      "{'loss': 0.8253, 'learning_rate': 0.00018179831097863886, 'epoch': 2.73}\n",
      "{'loss': 0.8666, 'learning_rate': 0.0001817651929127339, 'epoch': 2.74}\n",
      "{'loss': 1.0061, 'learning_rate': 0.00018173207484682894, 'epoch': 2.74}\n",
      "{'loss': 0.9505, 'learning_rate': 0.00018169895678092401, 'epoch': 2.75}\n",
      "{'loss': 0.922, 'learning_rate': 0.00018166583871501906, 'epoch': 2.75}\n",
      "{'loss': 0.882, 'learning_rate': 0.0001816327206491141, 'epoch': 2.76}\n",
      "{'loss': 0.7537, 'learning_rate': 0.00018159960258320914, 'epoch': 2.76}\n",
      "{'loss': 1.0483, 'learning_rate': 0.0001815664845173042, 'epoch': 2.77}\n",
      "{'loss': 1.1155, 'learning_rate': 0.00018153336645139925, 'epoch': 2.77}\n",
      "{'loss': 0.838, 'learning_rate': 0.0001815002483854943, 'epoch': 2.78}\n",
      "{'loss': 0.9675, 'learning_rate': 0.00018146713031958936, 'epoch': 2.78}\n",
      "{'loss': 0.7716, 'learning_rate': 0.0001814340122536844, 'epoch': 2.79}\n",
      "{'loss': 0.8736, 'learning_rate': 0.00018140089418777942, 'epoch': 2.79}\n",
      "{'loss': 0.8726, 'learning_rate': 0.0001813677761218745, 'epoch': 2.8}\n",
      "{'loss': 0.9436, 'learning_rate': 0.00018133465805596953, 'epoch': 2.8}\n",
      "{'loss': 0.8697, 'learning_rate': 0.00018130153999006458, 'epoch': 2.81}\n",
      "{'loss': 0.8718, 'learning_rate': 0.00018126842192415965, 'epoch': 2.81}\n",
      "{'loss': 0.8769, 'learning_rate': 0.0001812353038582547, 'epoch': 2.82}\n",
      "{'loss': 0.7635, 'learning_rate': 0.00018120218579234973, 'epoch': 2.82}\n",
      "{'loss': 0.8147, 'learning_rate': 0.00018116906772644477, 'epoch': 2.83}\n",
      "{'loss': 1.0065, 'learning_rate': 0.00018113594966053984, 'epoch': 2.83}\n",
      "{'loss': 0.9424, 'learning_rate': 0.00018110283159463488, 'epoch': 2.84}\n",
      "{'loss': 0.8985, 'learning_rate': 0.00018106971352872993, 'epoch': 2.84}\n",
      "{'loss': 0.8402, 'learning_rate': 0.000181036595462825, 'epoch': 2.85}\n",
      "{'loss': 0.9117, 'learning_rate': 0.00018100347739692004, 'epoch': 2.85}\n",
      "{'loss': 0.9334, 'learning_rate': 0.00018097035933101508, 'epoch': 2.86}\n",
      "{'loss': 1.0389, 'learning_rate': 0.00018093724126511012, 'epoch': 2.86}\n",
      "{'loss': 0.9808, 'learning_rate': 0.00018090412319920517, 'epoch': 2.87}\n",
      "{'loss': 0.8431, 'learning_rate': 0.0001808710051333002, 'epoch': 2.87}\n",
      "{'loss': 0.9438, 'learning_rate': 0.00018083788706739525, 'epoch': 2.88}\n",
      "{'loss': 0.919, 'learning_rate': 0.00018080476900149032, 'epoch': 2.88}\n",
      "{'loss': 0.8218, 'learning_rate': 0.00018077165093558536, 'epoch': 2.89}\n",
      "{'loss': 0.9106, 'learning_rate': 0.0001807385328696804, 'epoch': 2.89}\n",
      "{'loss': 1.0434, 'learning_rate': 0.00018070541480377547, 'epoch': 2.9}\n",
      "{'loss': 0.9824, 'learning_rate': 0.00018067229673787052, 'epoch': 2.9}\n",
      "{'loss': 0.8962, 'learning_rate': 0.00018063917867196556, 'epoch': 2.91}\n",
      "{'loss': 0.8635, 'learning_rate': 0.00018060606060606063, 'epoch': 2.91}\n",
      "{'loss': 0.9414, 'learning_rate': 0.00018057294254015567, 'epoch': 2.92}\n",
      "{'loss': 0.9394, 'learning_rate': 0.0001805398244742507, 'epoch': 2.92}\n",
      "{'loss': 0.8775, 'learning_rate': 0.00018050670640834578, 'epoch': 2.93}\n",
      "{'loss': 0.9002, 'learning_rate': 0.00018047358834244082, 'epoch': 2.93}\n",
      "{'loss': 0.8719, 'learning_rate': 0.00018044047027653587, 'epoch': 2.94}\n",
      "{'loss': 0.9072, 'learning_rate': 0.0001804073522106309, 'epoch': 2.94}\n",
      "{'loss': 0.8592, 'learning_rate': 0.00018037423414472595, 'epoch': 2.95}\n",
      "{'loss': 0.9204, 'learning_rate': 0.000180341116078821, 'epoch': 2.95}\n",
      "{'loss': 0.9062, 'learning_rate': 0.00018030799801291604, 'epoch': 2.96}\n",
      "{'loss': 0.8607, 'learning_rate': 0.0001802748799470111, 'epoch': 2.96}\n",
      "{'loss': 0.9078, 'learning_rate': 0.00018024176188110615, 'epoch': 2.97}\n",
      "{'loss': 0.9442, 'learning_rate': 0.0001802086438152012, 'epoch': 2.97}\n",
      "{'loss': 0.9857, 'learning_rate': 0.00018017552574929626, 'epoch': 2.98}\n",
      "{'loss': 0.9113, 'learning_rate': 0.0001801424076833913, 'epoch': 2.98}\n",
      "{'loss': 0.8122, 'learning_rate': 0.00018010928961748634, 'epoch': 2.99}\n",
      "{'loss': 0.7796, 'learning_rate': 0.0001800761715515814, 'epoch': 2.99}\n",
      "{'loss': 0.9134, 'learning_rate': 0.00018004305348567646, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11363\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016502857208251953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1421,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24aaa69e090425a88e85b614eddbc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../102722run\\checkpoint-6039\n",
      "Configuration saved in ../102722run\\checkpoint-6039\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0368103981018066, 'eval_accuracy': 0.7319369884713544, 'eval_runtime': 105.8044, 'eval_samples_per_second': 107.396, 'eval_steps_per_second': 13.43, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../102722run\\checkpoint-6039\\pytorch_model.bin\n",
      "Feature extractor saved in ../102722run\\checkpoint-6039\\preprocessor_config.json\n",
      "Feature extractor saved in ../102722run\\preprocessor_config.json\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[WinError 267] The directory name is invalid: 'C:\\\\Users\\\\truon\\\\AppData\\\\Local\\\\Temp\\\\tmp_1yi8akr\\\\lfs_progress'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:616\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 616\u001b[0m     os\u001b[39m.\u001b[39;49munlink(fullname)\n\u001b[0;32m    617\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\truon\\\\AppData\\\\Local\\\\Temp\\\\tmp_1yi8akr\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:802\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 802\u001b[0m     _os\u001b[39m.\u001b[39;49munlink(path)\n\u001b[0;32m    803\u001b[0m \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\truon\\\\AppData\\\\Local\\\\Temp\\\\tmp_1yi8akr\\\\lfs_progress'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\truon\\Documents\\projects\\food\\notebooks\\vit_transfer.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/truon/Documents/projects/food/notebooks/vit_transfer.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/truon/Documents/projects/food/notebooks/vit_transfer.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m trainer\u001b[39m.\u001b[39msave_model(output_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/truon/Documents/projects/food/notebooks/vit_transfer.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trainer\u001b[39m.\u001b[39mlog_metrics(\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, train_results\u001b[39m.\u001b[39mmetrics)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\trainer.py:1500\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1495\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[0;32m   1497\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1498\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1499\u001b[0m )\n\u001b[1;32m-> 1500\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1501\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1502\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1503\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1504\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1505\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\trainer.py:1834\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1831\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1833\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_epoch_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m-> 1834\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[0;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m DebugOption\u001b[39m.\u001b[39mTPU_METRICS_DEBUG \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mdebug:\n\u001b[0;32m   1837\u001b[0m     \u001b[39mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1838\u001b[0m         \u001b[39m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\trainer.py:2056\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_report_to_hp_search(trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2055\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[1;32m-> 2056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[0;32m   2057\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\trainer.py:2215\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[1;34m(self, model, trial, metrics)\u001b[0m\n\u001b[0;32m   2212\u001b[0m     torch\u001b[39m.\u001b[39msave(rng_states, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrng_state_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mprocess_index\u001b[39m}\u001b[39;00m\u001b[39m.pth\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m   2214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_push_from_checkpoint(output_dir)\n\u001b[0;32m   2217\u001b[0m \u001b[39m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[0;32m   2218\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\trainer.py:3382\u001b[0m, in \u001b[0;36mTrainer._push_from_checkpoint\u001b[1;34m(self, checkpoint_folder)\u001b[0m\n\u001b[0;32m   3380\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3381\u001b[0m         commit_message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining in progress, epoch \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 3382\u001b[0m     _, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpush_in_progress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepo\u001b[39m.\u001b[39;49mpush_to_hub(\n\u001b[0;32m   3383\u001b[0m         commit_message\u001b[39m=\u001b[39;49mcommit_message, blocking\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, auto_lfs_prune\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   3384\u001b[0m     )\n\u001b[0;32m   3385\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   3386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mhub_strategy \u001b[39m==\u001b[39m HubStrategy\u001b[39m.\u001b[39mCHECKPOINT:\n\u001b[0;32m   3387\u001b[0m         \u001b[39m# Move back the checkpoint to its place\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\huggingface_hub\\repository.py:1438\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[1;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1436\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_add(auto_lfs_track\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1437\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m-> 1438\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgit_push(\n\u001b[0;32m   1439\u001b[0m     upstream\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39morigin \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_branch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1440\u001b[0m     blocking\u001b[39m=\u001b[39;49mblocking,\n\u001b[0;32m   1441\u001b[0m     auto_lfs_prune\u001b[39m=\u001b[39;49mauto_lfs_prune,\n\u001b[0;32m   1442\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\huggingface_hub\\repository.py:1213\u001b[0m, in \u001b[0;36mRepository.git_push\u001b[1;34m(self, upstream, blocking, auto_lfs_prune)\u001b[0m\n\u001b[0;32m   1210\u001b[0m                 logger\u001b[39m.\u001b[39mwarning(stderr)\n\u001b[0;32m   1212\u001b[0m             \u001b[39mif\u001b[39;00m return_code:\n\u001b[1;32m-> 1213\u001b[0m                 \u001b[39mraise\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError(\n\u001b[0;32m   1214\u001b[0m                     return_code, process\u001b[39m.\u001b[39margs, output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr\n\u001b[0;32m   1215\u001b[0m                 )\n\u001b[0;32m   1217\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m   1218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(exc\u001b[39m.\u001b[39mstderr)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\contextlib.py:120\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m         \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    121\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\huggingface_hub\\repository.py:410\u001b[0m, in \u001b[0;36m_lfs_log_progress\u001b[1;34m()\u001b[0m\n\u001b[0;32m    407\u001b[0m exit_event\u001b[39m.\u001b[39mset()\n\u001b[0;32m    408\u001b[0m x\u001b[39m.\u001b[39mjoin()\n\u001b[1;32m--> 410\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mGIT_LFS_PROGRESS\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m current_lfs_progress_value\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:827\u001b[0m, in \u001b[0;36mTemporaryDirectory.__exit__\u001b[1;34m(self, exc, value, tb)\u001b[0m\n\u001b[0;32m    826\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc, value, tb):\n\u001b[1;32m--> 827\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcleanup()\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:831\u001b[0m, in \u001b[0;36mTemporaryDirectory.cleanup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcleanup\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    830\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_finalizer\u001b[39m.\u001b[39mdetach():\n\u001b[1;32m--> 831\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:813\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 813\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:740\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:618\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    616\u001b[0m             os\u001b[39m.\u001b[39munlink(fullname)\n\u001b[0;32m    617\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m             onerror(os\u001b[39m.\u001b[39;49munlink, fullname, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    619\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    620\u001b[0m     os\u001b[39m.\u001b[39mrmdir(path)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:805\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree.<locals>.onerror\u001b[1;34m(func, path, exc_info)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[39m# PermissionError is raised on FreeBSD for directories\u001b[39;00m\n\u001b[0;32m    804\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mIsADirectoryError\u001b[39;00m, \u001b[39mPermissionError\u001b[39;00m):\n\u001b[1;32m--> 805\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_rmtree(path)\n\u001b[0;32m    806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\tempfile.py:813\u001b[0m, in \u001b[0;36mTemporaryDirectory._rmtree\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    810\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    811\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[1;32m--> 813\u001b[0m _shutil\u001b[39m.\u001b[39;49mrmtree(name, onerror\u001b[39m=\u001b[39;49monerror)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:740\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    738\u001b[0m     \u001b[39m# can't continue even if onerror hook returns\u001b[39;00m\n\u001b[0;32m    739\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 740\u001b[0m \u001b[39mreturn\u001b[39;00m _rmtree_unsafe(path, onerror)\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:599\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    597\u001b[0m         entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m--> 599\u001b[0m     onerror(os\u001b[39m.\u001b[39;49mscandir, path, sys\u001b[39m.\u001b[39;49mexc_info())\n\u001b[0;32m    600\u001b[0m     entries \u001b[39m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m entries:\n",
      "File \u001b[1;32mc:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\shutil.py:596\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_rmtree_unsafe\u001b[39m(path, onerror):\n\u001b[0;32m    595\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         \u001b[39mwith\u001b[39;00m os\u001b[39m.\u001b[39;49mscandir(path) \u001b[39mas\u001b[39;00m scandir_it:\n\u001b[0;32m    597\u001b[0m             entries \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(scandir_it)\n\u001b[0;32m    598\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[1;31mNotADirectoryError\u001b[0m: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\truon\\\\AppData\\\\Local\\\\Temp\\\\tmp_1yi8akr\\\\lfs_progress'"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model(output_dir = \"./models/\")\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efa6cdb99600126c800a8c2796f4efb4f3deae8ebc43a754c2171b5bde04e09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
