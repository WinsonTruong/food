{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is using transfer learning from a ViT model from huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import transformers\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Food101\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
    "\n",
    "from datasets import load_metric, load_dataset\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from transformers import AutoFeatureExtractor\n",
    "from transformers import DefaultDataCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset food101 (C:\\Users\\truon\\.cache\\huggingface\\datasets\\food101\\default\\0.0.0\\7cebe41a80fb2da3f08fcbef769c8874073a86346f7fb96dc0847d4dfc318295)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4250, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(750, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "food = load_dataset(\"food101\", split=\"train[:5000]\")\n",
    "\n",
    "splits = food.train_test_split(test_size=0.15)\n",
    "train = splits['train']\n",
    "val = splits['test']\n",
    "\n",
    "display(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"image_std\": [\n",
       "    0.5,\n",
       "    0.5,\n",
       "    0.5\n",
       "  ],\n",
       "  \"resample\": 2,\n",
       "  \"size\": 224\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process image to tensor using ViT method (16x16 patches)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `AutoFeatureExtractor.from_pretrained()` method helps us make sure we are \n",
    "- (1) resizing the inputs to the appropriate size \n",
    "- (2) using the appropriate image mean and standard deviation for the model architecture we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 6,\n",
       " 'pixel_values': tensor([[[-0.1137, -0.1373, -0.1216,  ...,  0.3961,  0.3725,  0.0824],\n",
       "          [-0.0902, -0.1216, -0.1529,  ...,  0.4039,  0.1843, -0.0980],\n",
       "          [-0.0667, -0.1059, -0.1608,  ...,  0.4745,  0.2000, -0.0431],\n",
       "          ...,\n",
       "          [-0.9608, -0.9765, -0.9843,  ...,  0.3412,  0.4510,  0.3882],\n",
       "          [-0.9529, -0.9686, -0.9765,  ...,  0.5216,  0.5843,  0.5059],\n",
       "          [-0.9451, -0.9608, -0.9608,  ...,  0.6549,  0.6392,  0.5765]],\n",
       " \n",
       "         [[ 0.1451,  0.1373,  0.1529,  ...,  0.6549,  0.6235,  0.3333],\n",
       "          [ 0.1765,  0.1529,  0.1137,  ...,  0.6784,  0.4510,  0.1765],\n",
       "          [ 0.2078,  0.1529,  0.0824,  ...,  0.7569,  0.4824,  0.2392],\n",
       "          ...,\n",
       "          [-0.9529, -0.9608, -0.9686,  ...,  0.5922,  0.7020,  0.6392],\n",
       "          [-0.9451, -0.9608, -0.9608,  ...,  0.7569,  0.8196,  0.7412],\n",
       "          [-0.9373, -0.9529, -0.9529,  ...,  0.8902,  0.8667,  0.8039]],\n",
       " \n",
       "         [[ 0.3176,  0.3098,  0.3255,  ...,  0.7569,  0.7255,  0.4353],\n",
       "          [ 0.3490,  0.3176,  0.2784,  ...,  0.7882,  0.5608,  0.2784],\n",
       "          [ 0.3647,  0.3098,  0.2314,  ...,  0.8824,  0.6078,  0.3647],\n",
       "          ...,\n",
       "          [-0.9373, -0.9608, -0.9765,  ...,  0.7020,  0.8118,  0.7490],\n",
       "          [-0.9294, -0.9451, -0.9608,  ...,  0.8667,  0.9137,  0.8510],\n",
       "          [-0.9216, -0.9373, -0.9451,  ...,  0.9765,  0.9608,  0.9137]]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "_transforms = Compose(\n",
    "    [\n",
    "            RandomResizedCrop(feature_extractor.size)\n",
    "            ,ToTensor()\n",
    "            ,normalize\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def transforms(examples):\n",
    "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "    return examples\n",
    "\n",
    "# when the data is loaded, it will apply the transformation above\n",
    "train = train.with_transform(transforms)\n",
    "val = val.with_transform(transforms)\n",
    "\n",
    "# example of how our data is organized, dictionary with 2 key-value pairs\n",
    "train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 RGBs, 224 x 224 pixels\n",
    "train[0]['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DefaultDataCollator(return_tensors='pt')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~ creating a dataloader, creates batches \n",
    "# `pt` is for PyTorch Tensor\n",
    "data_collator = DefaultDataCollator()\n",
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "labels = train.features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=10,\n",
    "    fp16=True,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    save_total_limit=2,\n",
    "    remove_unused_columns=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"wandb\",\n",
    "    #push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer=feature_extractor,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\truon\\anaconda3\\envs\\learn\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4250\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1330\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015502691268920898,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1330,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca530514e2544424aa343bae0be1a9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1330 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3071, 'learning_rate': 0.00019849624060150375, 'epoch': 0.08}\n",
      "{'loss': 0.2252, 'learning_rate': 0.00019699248120300754, 'epoch': 0.15}\n",
      "{'loss': 0.1418, 'learning_rate': 0.00019548872180451127, 'epoch': 0.23}\n",
      "{'loss': 0.2298, 'learning_rate': 0.00019398496240601503, 'epoch': 0.3}\n",
      "{'loss': 0.1833, 'learning_rate': 0.0001924812030075188, 'epoch': 0.38}\n",
      "{'loss': 0.1479, 'learning_rate': 0.00019097744360902256, 'epoch': 0.45}\n",
      "{'loss': 0.1387, 'learning_rate': 0.00018947368421052632, 'epoch': 0.53}\n",
      "{'loss': 0.1216, 'learning_rate': 0.00018796992481203009, 'epoch': 0.6}\n",
      "{'loss': 0.1127, 'learning_rate': 0.00018646616541353382, 'epoch': 0.68}\n",
      "{'loss': 0.1442, 'learning_rate': 0.0001849624060150376, 'epoch': 0.75}\n",
      "{'loss': 0.2092, 'learning_rate': 0.00018345864661654135, 'epoch': 0.83}\n",
      "{'loss': 0.0971, 'learning_rate': 0.0001819548872180451, 'epoch': 0.9}\n",
      "{'loss': 0.2686, 'learning_rate': 0.00018045112781954887, 'epoch': 0.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015503168106079102,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550824d77d8a4d699b2c51deb9995114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-133\n",
      "Configuration saved in ./results\\checkpoint-133\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3834095001220703, 'eval_accuracy': 0.8933333333333333, 'eval_runtime': 7.0882, 'eval_samples_per_second': 105.809, 'eval_steps_per_second': 13.261, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-133\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-133\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1715, 'learning_rate': 0.00017894736842105264, 'epoch': 1.05}\n",
      "{'loss': 0.203, 'learning_rate': 0.0001774436090225564, 'epoch': 1.13}\n",
      "{'loss': 0.2424, 'learning_rate': 0.00017593984962406016, 'epoch': 1.2}\n",
      "{'loss': 0.2242, 'learning_rate': 0.0001744360902255639, 'epoch': 1.28}\n",
      "{'loss': 0.2288, 'learning_rate': 0.0001729323308270677, 'epoch': 1.35}\n",
      "{'loss': 0.2521, 'learning_rate': 0.00017142857142857143, 'epoch': 1.43}\n",
      "{'loss': 0.1919, 'learning_rate': 0.0001699248120300752, 'epoch': 1.5}\n",
      "{'loss': 0.2513, 'learning_rate': 0.00016842105263157895, 'epoch': 1.58}\n",
      "{'loss': 0.3379, 'learning_rate': 0.00016691729323308271, 'epoch': 1.65}\n",
      "{'loss': 0.2317, 'learning_rate': 0.00016541353383458648, 'epoch': 1.73}\n",
      "{'loss': 0.1691, 'learning_rate': 0.00016390977443609024, 'epoch': 1.8}\n",
      "{'loss': 0.3017, 'learning_rate': 0.00016240601503759398, 'epoch': 1.88}\n",
      "{'loss': 0.217, 'learning_rate': 0.00016090225563909777, 'epoch': 1.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016002416610717773,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340de9e525ef4b4c9507a2a138ae7680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-266\n",
      "Configuration saved in ./results\\checkpoint-266\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33890262246131897, 'eval_accuracy': 0.912, 'eval_runtime': 7.1448, 'eval_samples_per_second': 104.972, 'eval_steps_per_second': 13.157, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-266\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-266\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2092, 'learning_rate': 0.0001593984962406015, 'epoch': 2.03}\n",
      "{'loss': 0.2391, 'learning_rate': 0.00015789473684210527, 'epoch': 2.11}\n",
      "{'loss': 0.1928, 'learning_rate': 0.00015639097744360903, 'epoch': 2.18}\n",
      "{'loss': 0.1216, 'learning_rate': 0.0001548872180451128, 'epoch': 2.26}\n",
      "{'loss': 0.1626, 'learning_rate': 0.00015338345864661653, 'epoch': 2.33}\n",
      "{'loss': 0.1679, 'learning_rate': 0.00015187969924812032, 'epoch': 2.41}\n",
      "{'loss': 0.1718, 'learning_rate': 0.00015037593984962405, 'epoch': 2.48}\n",
      "{'loss': 0.2066, 'learning_rate': 0.00014887218045112784, 'epoch': 2.56}\n",
      "{'loss': 0.105, 'learning_rate': 0.00014736842105263158, 'epoch': 2.63}\n",
      "{'loss': 0.1982, 'learning_rate': 0.00014586466165413534, 'epoch': 2.71}\n",
      "{'loss': 0.275, 'learning_rate': 0.0001443609022556391, 'epoch': 2.78}\n",
      "{'loss': 0.1738, 'learning_rate': 0.00014285714285714287, 'epoch': 2.86}\n",
      "{'loss': 0.0918, 'learning_rate': 0.0001413533834586466, 'epoch': 2.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01900315284729004,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562442dc09514bbe9999bb8f385a87d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-399\n",
      "Configuration saved in ./results\\checkpoint-399\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33352261781692505, 'eval_accuracy': 0.8986666666666666, 'eval_runtime': 7.2128, 'eval_samples_per_second': 103.982, 'eval_steps_per_second': 13.032, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-399\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-399\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-133] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1747, 'learning_rate': 0.0001398496240601504, 'epoch': 3.01}\n",
      "{'loss': 0.2128, 'learning_rate': 0.00013834586466165413, 'epoch': 3.08}\n",
      "{'loss': 0.1345, 'learning_rate': 0.0001368421052631579, 'epoch': 3.16}\n",
      "{'loss': 0.1051, 'learning_rate': 0.00013533834586466166, 'epoch': 3.23}\n",
      "{'loss': 0.2034, 'learning_rate': 0.00013383458646616542, 'epoch': 3.31}\n",
      "{'loss': 0.2135, 'learning_rate': 0.00013233082706766918, 'epoch': 3.38}\n",
      "{'loss': 0.1409, 'learning_rate': 0.00013082706766917294, 'epoch': 3.46}\n",
      "{'loss': 0.1084, 'learning_rate': 0.00012932330827067668, 'epoch': 3.53}\n",
      "{'loss': 0.1449, 'learning_rate': 0.00012781954887218047, 'epoch': 3.61}\n",
      "{'loss': 0.1265, 'learning_rate': 0.0001263157894736842, 'epoch': 3.68}\n",
      "{'loss': 0.1387, 'learning_rate': 0.00012481203007518797, 'epoch': 3.76}\n",
      "{'loss': 0.1593, 'learning_rate': 0.00012330827067669173, 'epoch': 3.83}\n",
      "{'loss': 0.2145, 'learning_rate': 0.0001218045112781955, 'epoch': 3.91}\n",
      "{'loss': 0.2231, 'learning_rate': 0.00012030075187969925, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015503168106079102,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333b84bfe28041c0a2059c0d1c899657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-532\n",
      "Configuration saved in ./results\\checkpoint-532\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30968499183654785, 'eval_accuracy': 0.9066666666666666, 'eval_runtime': 7.0057, 'eval_samples_per_second': 107.055, 'eval_steps_per_second': 13.418, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-532\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-532\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-399] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1108, 'learning_rate': 0.00011879699248120302, 'epoch': 4.06}\n",
      "{'loss': 0.1266, 'learning_rate': 0.00011729323308270677, 'epoch': 4.14}\n",
      "{'loss': 0.1448, 'learning_rate': 0.00011578947368421053, 'epoch': 4.21}\n",
      "{'loss': 0.1426, 'learning_rate': 0.00011428571428571428, 'epoch': 4.29}\n",
      "{'loss': 0.0821, 'learning_rate': 0.00011278195488721806, 'epoch': 4.36}\n",
      "{'loss': 0.0769, 'learning_rate': 0.00011127819548872181, 'epoch': 4.44}\n",
      "{'loss': 0.0775, 'learning_rate': 0.00010977443609022557, 'epoch': 4.51}\n",
      "{'loss': 0.0913, 'learning_rate': 0.00010827067669172932, 'epoch': 4.59}\n",
      "{'loss': 0.1402, 'learning_rate': 0.0001067669172932331, 'epoch': 4.66}\n",
      "{'loss': 0.1133, 'learning_rate': 0.00010526315789473685, 'epoch': 4.74}\n",
      "{'loss': 0.0647, 'learning_rate': 0.00010375939849624061, 'epoch': 4.81}\n",
      "{'loss': 0.2037, 'learning_rate': 0.00010225563909774436, 'epoch': 4.89}\n",
      "{'loss': 0.1217, 'learning_rate': 0.00010075187969924814, 'epoch': 4.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01750326156616211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1e23b5392245a8b97c06cbdc23ab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-665\n",
      "Configuration saved in ./results\\checkpoint-665\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3296864330768585, 'eval_accuracy': 0.9093333333333333, 'eval_runtime': 7.2518, 'eval_samples_per_second': 103.423, 'eval_steps_per_second': 12.962, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-665\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-665\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-532] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0954, 'learning_rate': 9.924812030075187e-05, 'epoch': 5.04}\n",
      "{'loss': 0.1289, 'learning_rate': 9.774436090225564e-05, 'epoch': 5.11}\n",
      "{'loss': 0.1183, 'learning_rate': 9.62406015037594e-05, 'epoch': 5.19}\n",
      "{'loss': 0.1103, 'learning_rate': 9.473684210526316e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0825, 'learning_rate': 9.323308270676691e-05, 'epoch': 5.34}\n",
      "{'loss': 0.1384, 'learning_rate': 9.172932330827067e-05, 'epoch': 5.41}\n",
      "{'loss': 0.0947, 'learning_rate': 9.022556390977444e-05, 'epoch': 5.49}\n",
      "{'loss': 0.0749, 'learning_rate': 8.87218045112782e-05, 'epoch': 5.56}\n",
      "{'loss': 0.1132, 'learning_rate': 8.721804511278195e-05, 'epoch': 5.64}\n",
      "{'loss': 0.0967, 'learning_rate': 8.571428571428571e-05, 'epoch': 5.71}\n",
      "{'loss': 0.1536, 'learning_rate': 8.421052631578948e-05, 'epoch': 5.79}\n",
      "{'loss': 0.1011, 'learning_rate': 8.270676691729324e-05, 'epoch': 5.86}\n",
      "{'loss': 0.0857, 'learning_rate': 8.120300751879699e-05, 'epoch': 5.94}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018002986907958984,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e182829e8544688987375fdfe3eab0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-798\n",
      "Configuration saved in ./results\\checkpoint-798\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2937006950378418, 'eval_accuracy': 0.9133333333333333, 'eval_runtime': 7.1688, 'eval_samples_per_second': 104.621, 'eval_steps_per_second': 13.112, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-798\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-798\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-266] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0815, 'learning_rate': 7.969924812030075e-05, 'epoch': 6.02}\n",
      "{'loss': 0.0497, 'learning_rate': 7.819548872180451e-05, 'epoch': 6.09}\n",
      "{'loss': 0.0648, 'learning_rate': 7.669172932330826e-05, 'epoch': 6.17}\n",
      "{'loss': 0.1153, 'learning_rate': 7.518796992481203e-05, 'epoch': 6.24}\n",
      "{'loss': 0.1235, 'learning_rate': 7.368421052631579e-05, 'epoch': 6.32}\n",
      "{'loss': 0.1117, 'learning_rate': 7.218045112781955e-05, 'epoch': 6.39}\n",
      "{'loss': 0.0539, 'learning_rate': 7.06766917293233e-05, 'epoch': 6.47}\n",
      "{'loss': 0.0819, 'learning_rate': 6.917293233082706e-05, 'epoch': 6.54}\n",
      "{'loss': 0.1019, 'learning_rate': 6.766917293233083e-05, 'epoch': 6.62}\n",
      "{'loss': 0.0415, 'learning_rate': 6.616541353383459e-05, 'epoch': 6.69}\n",
      "{'loss': 0.0442, 'learning_rate': 6.466165413533834e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0314, 'learning_rate': 6.31578947368421e-05, 'epoch': 6.84}\n",
      "{'loss': 0.043, 'learning_rate': 6.165413533834587e-05, 'epoch': 6.92}\n",
      "{'loss': 0.0922, 'learning_rate': 6.015037593984962e-05, 'epoch': 6.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015502452850341797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f252f4442d411f9999a1bf24227aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-931\n",
      "Configuration saved in ./results\\checkpoint-931\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27657610177993774, 'eval_accuracy': 0.9253333333333333, 'eval_runtime': 7.1368, 'eval_samples_per_second': 105.09, 'eval_steps_per_second': 13.171, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-931\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-931\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-665] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0447, 'learning_rate': 5.8646616541353386e-05, 'epoch': 7.07}\n",
      "{'loss': 0.082, 'learning_rate': 5.714285714285714e-05, 'epoch': 7.14}\n",
      "{'loss': 0.0638, 'learning_rate': 5.5639097744360905e-05, 'epoch': 7.22}\n",
      "{'loss': 0.1124, 'learning_rate': 5.413533834586466e-05, 'epoch': 7.29}\n",
      "{'loss': 0.0534, 'learning_rate': 5.2631578947368424e-05, 'epoch': 7.37}\n",
      "{'loss': 0.0543, 'learning_rate': 5.112781954887218e-05, 'epoch': 7.44}\n",
      "{'loss': 0.0779, 'learning_rate': 4.9624060150375936e-05, 'epoch': 7.52}\n",
      "{'loss': 0.0578, 'learning_rate': 4.81203007518797e-05, 'epoch': 7.59}\n",
      "{'loss': 0.0898, 'learning_rate': 4.6616541353383456e-05, 'epoch': 7.67}\n",
      "{'loss': 0.1046, 'learning_rate': 4.511278195488722e-05, 'epoch': 7.74}\n",
      "{'loss': 0.1118, 'learning_rate': 4.3609022556390975e-05, 'epoch': 7.82}\n",
      "{'loss': 0.0285, 'learning_rate': 4.210526315789474e-05, 'epoch': 7.89}\n",
      "{'loss': 0.1242, 'learning_rate': 4.0601503759398494e-05, 'epoch': 7.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017002582550048828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "180b7e6059f4409abcbeeeb92d62a674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1064\n",
      "Configuration saved in ./results\\checkpoint-1064\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28264448046684265, 'eval_accuracy': 0.9306666666666666, 'eval_runtime': 7.2713, 'eval_samples_per_second': 103.146, 'eval_steps_per_second': 12.928, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1064\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-1064\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-798] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0379, 'learning_rate': 3.909774436090226e-05, 'epoch': 8.05}\n",
      "{'loss': 0.1233, 'learning_rate': 3.759398496240601e-05, 'epoch': 8.12}\n",
      "{'loss': 0.0744, 'learning_rate': 3.6090225563909776e-05, 'epoch': 8.2}\n",
      "{'loss': 0.1187, 'learning_rate': 3.458646616541353e-05, 'epoch': 8.27}\n",
      "{'loss': 0.0335, 'learning_rate': 3.3082706766917295e-05, 'epoch': 8.35}\n",
      "{'loss': 0.0412, 'learning_rate': 3.157894736842105e-05, 'epoch': 8.42}\n",
      "{'loss': 0.0892, 'learning_rate': 3.007518796992481e-05, 'epoch': 8.5}\n",
      "{'loss': 0.0763, 'learning_rate': 2.857142857142857e-05, 'epoch': 8.57}\n",
      "{'loss': 0.0858, 'learning_rate': 2.706766917293233e-05, 'epoch': 8.65}\n",
      "{'loss': 0.0541, 'learning_rate': 2.556390977443609e-05, 'epoch': 8.72}\n",
      "{'loss': 0.0788, 'learning_rate': 2.406015037593985e-05, 'epoch': 8.8}\n",
      "{'loss': 0.0553, 'learning_rate': 2.255639097744361e-05, 'epoch': 8.87}\n",
      "{'loss': 0.0931, 'learning_rate': 2.105263157894737e-05, 'epoch': 8.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01750349998474121,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf855b6077c4b6c9c9abb03d9bebe5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1197\n",
      "Configuration saved in ./results\\checkpoint-1197\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26141634583473206, 'eval_accuracy': 0.9306666666666666, 'eval_runtime': 7.0912, 'eval_samples_per_second': 105.764, 'eval_steps_per_second': 13.256, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1197\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-1197\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-931] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1062, 'learning_rate': 1.954887218045113e-05, 'epoch': 9.02}\n",
      "{'loss': 0.05, 'learning_rate': 1.8045112781954888e-05, 'epoch': 9.1}\n",
      "{'loss': 0.0583, 'learning_rate': 1.6541353383458648e-05, 'epoch': 9.17}\n",
      "{'loss': 0.0755, 'learning_rate': 1.5037593984962406e-05, 'epoch': 9.25}\n",
      "{'loss': 0.085, 'learning_rate': 1.3533834586466165e-05, 'epoch': 9.32}\n",
      "{'loss': 0.0264, 'learning_rate': 1.2030075187969925e-05, 'epoch': 9.4}\n",
      "{'loss': 0.0944, 'learning_rate': 1.0526315789473684e-05, 'epoch': 9.47}\n",
      "{'loss': 0.092, 'learning_rate': 9.022556390977444e-06, 'epoch': 9.55}\n",
      "{'loss': 0.0299, 'learning_rate': 7.518796992481203e-06, 'epoch': 9.62}\n",
      "{'loss': 0.0693, 'learning_rate': 6.015037593984962e-06, 'epoch': 9.7}\n",
      "{'loss': 0.0461, 'learning_rate': 4.511278195488722e-06, 'epoch': 9.77}\n",
      "{'loss': 0.0241, 'learning_rate': 3.007518796992481e-06, 'epoch': 9.85}\n",
      "{'loss': 0.017, 'learning_rate': 1.5037593984962406e-06, 'epoch': 9.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 750\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0728, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017003536224365234,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 94,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f96186b4114460f8bb638f7a8fca553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-1330\n",
      "Configuration saved in ./results\\checkpoint-1330\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2562807500362396, 'eval_accuracy': 0.9306666666666666, 'eval_runtime': 7.0987, 'eval_samples_per_second': 105.652, 'eval_steps_per_second': 13.242, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-1330\\pytorch_model.bin\n",
      "Feature extractor saved in ./results\\checkpoint-1330\\preprocessor_config.json\n",
      "Deleting older checkpoint [results\\checkpoint-1197] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results\\checkpoint-1064 (score: 0.9306666666666666).\n",
      "Saving model checkpoint to ./models/\n",
      "Configuration saved in ./models/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 729.4853, 'train_samples_per_second': 58.26, 'train_steps_per_second': 1.823, 'train_loss': 0.12560736727445646, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./models/pytorch_model.bin\n",
      "Feature extractor saved in ./models/preprocessor_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  train_loss               =     0.1256\n",
      "  train_runtime            = 0:12:09.48\n",
      "  train_samples_per_second =      58.26\n",
      "  train_steps_per_second   =      1.823\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model(output_dir = \"./models/\")\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6efa6cdb99600126c800a8c2796f4efb4f3deae8ebc43a754c2171b5bde04e09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
